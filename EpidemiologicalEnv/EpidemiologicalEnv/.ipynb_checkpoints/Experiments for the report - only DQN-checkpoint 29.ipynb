{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import json\n",
    "import datetime as dt\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "#from stable_baselines import TRPO\n",
    "from BedEpidemicIntervention.envs.BedEpidemicInterventionEnv import BedEpidemicInterventionEnv\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "import copy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from DQN2 import DQN2\n",
    "import time\n",
    "from DQN import DQN\n",
    "\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def plot_res(values, title=''):   \n",
    "    ''' Plot the reward curve and histogram of results over time.'''\n",
    "    # Update the window after each episode\n",
    "    #clear_output(wait=True)\n",
    "    \n",
    "    averaged_values = []\n",
    "    k=100\n",
    "    for i in range(len(values)):\n",
    "        if i<k:\n",
    "            averaged_values.append(values[i])\n",
    "        else:\n",
    "            averaged_values.append(sum(values[i-k:i])/k)\n",
    "    #print(values)\n",
    "    #print(averaged_values)\n",
    "        \n",
    "    # Define the figure\n",
    "    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,5))\n",
    "    f.suptitle(title)\n",
    "    ax.plot(averaged_values, label='score per run')\n",
    "    ax.axhline(195, c='red',ls='--', label='goal')\n",
    "    ax.set_xlabel('Episodes')\n",
    "    ax.set_ylabel('Reward')\n",
    "    x = range(len(averaged_values))\n",
    "    ax.legend()\n",
    "    # Calculate the trend\n",
    "    try:\n",
    "        z = np.polyfit(x, averaged_values, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax[0].plot(x,p(x),\"--\", label='trend')\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, model, episodes=1000, gamma=0.95, \n",
    "               epsilon=0.02, eps_decay=0.99,\n",
    "               replay=False, replay_size=10000, \n",
    "               title = 'DQL', double=False, \n",
    "               n_update=10, soft=False, verbose=True):\n",
    "    \"\"\"Deep Q Learning algorithm using the DQN. \"\"\"\n",
    "    final = []\n",
    "    memory = []\n",
    "    episode_i=0\n",
    "    last = False\n",
    "    i=0\n",
    "    sum_total_replay_time=0\n",
    "    for episode in range(episodes):\n",
    "        if i==episodes-1:\n",
    "            last=True\n",
    "        episode_i+=1\n",
    "        if double and not soft:\n",
    "            # Update target network every n_update steps\n",
    "            if episode % n_update == 0:\n",
    "                model.target_update()\n",
    "        if double and soft:\n",
    "            model.target_update()\n",
    "        \n",
    "        # Reset state\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Implement greedy search policy to explore the state space\n",
    "            if random.random() >= epsilon or last:\n",
    "                q_values = model.predict(state)\n",
    "                #print(\"Q values==\",q_values)\n",
    "                #rint(\"torch.argmax(q_values)\",torch.argmax(q_values))\n",
    "\n",
    "                action = torch.argmax(q_values).item()\n",
    "                #print(\"Predicted action=\",action)\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "                #print(\"Sampled action\",action)\n",
    "            # Take action and add reward to total\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Update total and memory\n",
    "            total += reward\n",
    "            memory.append((state, action, next_state, reward, done))\n",
    "            if len(memory)>10000:\n",
    "                memory = memory[len(memory)-10000:len(memory)]\n",
    "            q_values = model.predict(state).tolist()\n",
    "             \n",
    "            if done:\n",
    "                if not replay:\n",
    "                    q_values[action] = reward\n",
    "                    # Update network weights\n",
    "                    #print(\"state==\",state)\n",
    "                    #print(\"q value==\",q_values)\n",
    "                    model.update(state, q_values)\n",
    "                break\n",
    "\n",
    "            if replay:\n",
    "                t0=time.time()\n",
    "                # Update network weights using replay memory\n",
    "                model.replay(memory, replay_size, gamma)\n",
    "                t1=time.time()\n",
    "                sum_total_replay_time+=(t1-t0)\n",
    "            else: \n",
    "                # Update network weights using the last step only\n",
    "                q_values_next = model.predict(next_state)\n",
    "                #print(q_values)\n",
    "                #print(action)\n",
    "                q_values[action] = reward + gamma * torch.max(q_values_next).item()\n",
    "                #print(\"state==\",state)\n",
    "                #print(\"q value==\",q_values)\n",
    "                model.update(state, q_values)\n",
    "\n",
    "            state = next_state\n",
    "        \n",
    "        # Update epsilon\n",
    "        epsilon = max(epsilon * eps_decay, 0.02)\n",
    "        final.append(total)\n",
    "        if episode ==episodes-1:\n",
    "            print(\"plotting reward\")\n",
    "            #plot_res(final, title)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"episode: {}, total reward: {}\".format(episode_i, total))\n",
    "            if replay:\n",
    "                print(\"Average replay time:\", sum_total_replay_time/episode_i)\n",
    "        i+=1\n",
    "    return final\n",
    "def dqn_train_render(time_steps,episodes,log_dir='dqn_log_dir'):\n",
    "    env = gym.make('BedEpidemicIntervention:bed-epidemic-intervention-v0')\n",
    "    # Number of states\n",
    "    n_state = env.observation_space.shape[0]\n",
    "    # Number of actions\n",
    "    n_action = env.action_space.n\n",
    "    # Number of episodes\n",
    " \n",
    "    # Number of hidden nodes in the DQN\n",
    "    n_hidden = 64\n",
    "    # Learning rate\n",
    "    lr = 0.001\n",
    "    simple_dqn = DQN(n_state, n_action, n_hidden, lr)\n",
    "    y = q_learning(env, simple_dqn, episodes, gamma=.95, epsilon=0.05,replay=False)\n",
    "\n",
    "    return y,simple_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo2_train_render(time_steps,log_dir='ppo2_log_dir'):\n",
    "    env = gym.make('BedEpidemicIntervention:bed-epidemic-intervention-v0')\n",
    "    env = Monitor(env, log_dir)\n",
    "    callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    model = PPO2(MlpPolicy, env, verbose=1,learning_rate=0.001,n_steps=128, )\n",
    "    model.learn(total_timesteps=time_steps,callback=callback)\n",
    "    x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "    \n",
    "    return y,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_rewards(rewards, k=10):\n",
    "    averaged_rewards = []\n",
    "    \n",
    "    for i in range(len(rewards)):\n",
    "        if i<k:\n",
    "            averaged_rewards.append(rewards[i])\n",
    "        else:\n",
    "            averaged_rewards.append(sum(rewards[i-k:i])/k)\n",
    "    return averaged_rewards\n",
    "\n",
    "\n",
    "def run_algos_plot(time_steps,episodes=1000):\n",
    "    env = gym.make('BedEpidemicIntervention:bed-epidemic-intervention-v0')\n",
    "    \n",
    "    dqn_rewards,dqn_model = dqn_train_render(time_steps,episodes)\n",
    "    #ppo2_rewards,ppo2_model = ppo2_train_render(time_steps)\n",
    "    dqn_averaged = get_averaged_rewards(dqn_rewards)\n",
    "    #ppo2_averaged = get_averaged_rewards(ppo2_rewards)\n",
    "    #min_len = min(len(dqn_averaged),len(ppo2_averaged))\n",
    "    #dqn_averaged = dqn_averaged[:min_len]\n",
    "    #ppo2_averaged = ppo2_averaged[:min_len]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    obs = env.reset()\n",
    "    i=0\n",
    "    done= False\n",
    "    print(\"DQN**********************************************\")\n",
    "    while not done:\n",
    "        q_values = dqn_model.predict(obs)\n",
    "        action = torch.argmax(q_values).item()\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        i+=1\n",
    "    env.render()\n",
    "    '''  \n",
    "    obs = env.reset()\n",
    "    i=0\n",
    "    done= False\n",
    "    print(\"PPO2**********************************************\")\n",
    "    while not done:\n",
    "        action, _states = ppo2_model.predict(obs)\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        i+=1\n",
    "    env.render()\n",
    "    '''\n",
    "    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,5))\n",
    "    \n",
    "    ax.plot(dqn_averaged, label='DQN')\n",
    "    ax.set_xlabel('Episodes')\n",
    "    ax.set_ylabel('Last 10 Average Reward')\n",
    "    \n",
    "    ax.legend()\n",
    "    # Calculate the trend\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Total number of infected people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'BedEpidemicIntervention.envs.BedEpidemicInterventionEnv.BedEpidemicInterventionEnv'>\n",
      "<class 'BedEpidemicIntervention.envs.BedEpidemicInterventionEnv.BedEpidemicInterventionEnv'>\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 4.9072187e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 1.95e-05       |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 1              |\n",
      "| policy_entropy     | 1.3862898      |\n",
      "| policy_loss        | -0.00050496636 |\n",
      "| serial_timesteps   | 128            |\n",
      "| time_elapsed       | 7.61e-05       |\n",
      "| total_timesteps    | 128            |\n",
      "| value_loss         | 3754350.0      |\n",
      "---------------------------------------\n",
      "Reward -124294.0\n",
      "-------------------------------------\n",
      "| approxkl           | 1.875782e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 243          |\n",
      "| ep_reward_mean     | -1.25e+05    |\n",
      "| explained_variance | 3.43e-05     |\n",
      "| fps                | 330          |\n",
      "| n_updates          | 2            |\n",
      "| policy_entropy     | 1.3862104    |\n",
      "| policy_loss        | 0.0004517996 |\n",
      "| serial_timesteps   | 256          |\n",
      "| time_elapsed       | 5.24         |\n",
      "| total_timesteps    | 256          |\n",
      "| value_loss         | 99039450.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.7436156e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 243           |\n",
      "| ep_reward_mean     | -1.25e+05     |\n",
      "| explained_variance | 0.000228      |\n",
      "| fps                | 324           |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 1.386104      |\n",
      "| policy_loss        | 1.3235724e-05 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 5.63          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 14071248.0    |\n",
      "--------------------------------------\n",
      "Reward -138288.0\n",
      "---------------------------------------\n",
      "| approxkl           | 5.824725e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 250            |\n",
      "| ep_reward_mean     | -1.32e+05      |\n",
      "| explained_variance | 5.08e-05       |\n",
      "| fps                | 318            |\n",
      "| n_updates          | 4              |\n",
      "| policy_entropy     | 1.3861847      |\n",
      "| policy_loss        | -0.00030911318 |\n",
      "| serial_timesteps   | 512            |\n",
      "| time_elapsed       | 6.02           |\n",
      "| total_timesteps    | 512            |\n",
      "| value_loss         | 99149144.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00010210934  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 250            |\n",
      "| ep_reward_mean     | -1.32e+05      |\n",
      "| explained_variance | 0.000446       |\n",
      "| fps                | 251            |\n",
      "| n_updates          | 5              |\n",
      "| policy_entropy     | 1.385362       |\n",
      "| policy_loss        | -0.00096862536 |\n",
      "| serial_timesteps   | 640            |\n",
      "| time_elapsed       | 6.43           |\n",
      "| total_timesteps    | 640            |\n",
      "| value_loss         | 18528182.0     |\n",
      "---------------------------------------\n",
      "Reward -130290.0\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1370222e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 247           |\n",
      "| ep_reward_mean     | -1.32e+05     |\n",
      "| explained_variance | 6.2e-05       |\n",
      "| fps                | 267           |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 1.3856893     |\n",
      "| policy_loss        | 3.072177e-05  |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 6.94          |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 84973400.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.417301e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 247            |\n",
      "| ep_reward_mean     | -1.32e+05      |\n",
      "| explained_variance | 0.000591       |\n",
      "| fps                | 263            |\n",
      "| n_updates          | 7              |\n",
      "| policy_entropy     | 1.3841407      |\n",
      "| policy_loss        | -0.00062456913 |\n",
      "| serial_timesteps   | 896            |\n",
      "| time_elapsed       | 7.42           |\n",
      "| total_timesteps    | 896            |\n",
      "| value_loss         | 32213136.0     |\n",
      "---------------------------------------\n",
      "Reward -145150.0\n",
      "Num timesteps: 1000\n",
      "Best mean reward: -inf - Last mean reward per episode: -135505.50\n",
      "Saving new best model to ppo2_log_dir/best_model\n",
      "--------------------------------------\n",
      "| approxkl           | 3.9096067e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 250           |\n",
      "| ep_reward_mean     | -1.36e+05     |\n",
      "| explained_variance | 3.56e-05      |\n",
      "| fps                | 191           |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 1.3861085     |\n",
      "| policy_loss        | 0.0011657776  |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 7.91          |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 86048776.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9214327e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 250           |\n",
      "| ep_reward_mean     | -1.36e+05     |\n",
      "| explained_variance | 0.000757      |\n",
      "| fps                | 298           |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 1.3858956     |\n",
      "| policy_loss        | 0.00023227534 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 8.58          |\n",
      "| total_timesteps    | 1152          |\n",
      "| value_loss         | 23299864.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.2081785e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 250            |\n",
      "| ep_reward_mean     | -1.36e+05      |\n",
      "| explained_variance | 0.000163       |\n",
      "| fps                | 210            |\n",
      "| n_updates          | 10             |\n",
      "| policy_entropy     | 1.3861264      |\n",
      "| policy_loss        | -0.00034947367 |\n",
      "| serial_timesteps   | 1280           |\n",
      "| time_elapsed       | 9.01           |\n",
      "| total_timesteps    | 1280           |\n",
      "| value_loss         | 113274380.0    |\n",
      "---------------------------------------\n",
      "Reward -174976.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014383186 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 259           |\n",
      "| ep_reward_mean     | -1.44e+05     |\n",
      "| explained_variance | -0.000137     |\n",
      "| fps                | 238           |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 1.3857621     |\n",
      "| policy_loss        | 0.00024277938 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 9.62          |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 2249899.0     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002165393 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 259          |\n",
      "| ep_reward_mean     | -1.44e+05    |\n",
      "| explained_variance | 0.000729     |\n",
      "| fps                | 226          |\n",
      "| n_updates          | 12           |\n",
      "| policy_entropy     | 1.3838443    |\n",
      "| policy_loss        | -0.000774135 |\n",
      "| serial_timesteps   | 1536         |\n",
      "| time_elapsed       | 10.2         |\n",
      "| total_timesteps    | 1536         |\n",
      "| value_loss         | 111621420.0  |\n",
      "-------------------------------------\n",
      "Reward -144162.0\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000119988676 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 260            |\n",
      "| ep_reward_mean     | -1.44e+05      |\n",
      "| explained_variance | -0.000128      |\n",
      "| fps                | 195            |\n",
      "| n_updates          | 13             |\n",
      "| policy_entropy     | 1.3842403      |\n",
      "| policy_loss        | 0.0003378793   |\n",
      "| serial_timesteps   | 1664           |\n",
      "| time_elapsed       | 10.7           |\n",
      "| total_timesteps    | 1664           |\n",
      "| value_loss         | 7492229.0      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014573968  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 260           |\n",
      "| ep_reward_mean     | -1.44e+05     |\n",
      "| explained_variance | 0.000739      |\n",
      "| fps                | 244           |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 1.3714257     |\n",
      "| policy_loss        | -0.0023746584 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 11.4          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 109676640.0   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -136228.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011363595 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 259          |\n",
      "| ep_reward_mean     | -1.43e+05    |\n",
      "| explained_variance | -0.00021     |\n",
      "| fps                | 218          |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 1.3632798    |\n",
      "| policy_loss        | 0.0018809559 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 11.9         |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 4534784.5    |\n",
      "-------------------------------------\n",
      "Num timesteps: 2000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -142912.57\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018560344  |\n",
      "| clipfrac           | 0.015625      |\n",
      "| ep_len_mean        | 259           |\n",
      "| ep_reward_mean     | -1.43e+05     |\n",
      "| explained_variance | 0.000801      |\n",
      "| fps                | 282           |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 1.3196086     |\n",
      "| policy_loss        | -0.0020906383 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 12.5          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 112628456.0   |\n",
      "--------------------------------------\n",
      "Reward -140296.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0030746432  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 258           |\n",
      "| ep_reward_mean     | -1.43e+05     |\n",
      "| explained_variance | -0.000144     |\n",
      "| fps                | 280           |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 1.3043958     |\n",
      "| policy_loss        | 0.00089854095 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 13            |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 4038544.0     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0031911558 |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| ep_len_mean        | 258          |\n",
      "| ep_reward_mean     | -1.43e+05    |\n",
      "| explained_variance | 0.000756     |\n",
      "| fps                | 337          |\n",
      "| n_updates          | 18           |\n",
      "| policy_entropy     | 1.1582048    |\n",
      "| policy_loss        | 0.0011172431 |\n",
      "| serial_timesteps   | 2304         |\n",
      "| time_elapsed       | 13.4         |\n",
      "| total_timesteps    | 2304         |\n",
      "| value_loss         | 113515390.0  |\n",
      "-------------------------------------\n",
      "Reward -130486.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039330657 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 256           |\n",
      "| ep_reward_mean     | -1.41e+05     |\n",
      "| explained_variance | -4.39e-05     |\n",
      "| fps                | 287           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 1.2287167     |\n",
      "| policy_loss        | 0.00093556754 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 13.8          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 103744.2      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0037877103  |\n",
      "| clipfrac           | 0.029296875   |\n",
      "| ep_len_mean        | 256           |\n",
      "| ep_reward_mean     | -1.41e+05     |\n",
      "| explained_variance | 0.000582      |\n",
      "| fps                | 273           |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 1.1354362     |\n",
      "| policy_loss        | -0.0028249852 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 14.2          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 68397950.0    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017796766 |\n",
      "| clipfrac           | 0.021484375  |\n",
      "| ep_len_mean        | 256          |\n",
      "| ep_reward_mean     | -1.41e+05    |\n",
      "| explained_variance | 0.000102     |\n",
      "| fps                | 266          |\n",
      "| n_updates          | 21           |\n",
      "| policy_entropy     | 1.1776595    |\n",
      "| policy_loss        | 1.697545e-05 |\n",
      "| serial_timesteps   | 2688         |\n",
      "| time_elapsed       | 14.7         |\n",
      "| total_timesteps    | 2688         |\n",
      "| value_loss         | 113513960.0  |\n",
      "-------------------------------------\n",
      "Reward -239606.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045084144 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 272           |\n",
      "| ep_reward_mean     | -1.51e+05     |\n",
      "| explained_variance | -4.05e-06     |\n",
      "| fps                | 275           |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 1.2127402     |\n",
      "| policy_loss        | -0.0014505491 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 15.2          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 16827980.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00022877048  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 272            |\n",
      "| ep_reward_mean     | -1.51e+05      |\n",
      "| explained_variance | 0.000818       |\n",
      "| fps                | 263            |\n",
      "| n_updates          | 23             |\n",
      "| policy_entropy     | 1.147953       |\n",
      "| policy_loss        | -0.00069534814 |\n",
      "| serial_timesteps   | 2944           |\n",
      "| time_elapsed       | 15.7           |\n",
      "| total_timesteps    | 2944           |\n",
      "| value_loss         | 23374956.0     |\n",
      "---------------------------------------\n",
      "Num timesteps: 3000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -151377.60\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004017987   |\n",
      "| clipfrac           | 0.03125       |\n",
      "| ep_len_mean        | 272           |\n",
      "| ep_reward_mean     | -1.51e+05     |\n",
      "| explained_variance | 0.000378      |\n",
      "| fps                | 270           |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 1.1078246     |\n",
      "| policy_loss        | -0.0046143983 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 16.2          |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 113485304.0   |\n",
      "--------------------------------------\n",
      "Reward -248534.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015438902  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 287           |\n",
      "| ep_reward_mean     | -1.6e+05      |\n",
      "| explained_variance | 1.79e-07      |\n",
      "| fps                | 239           |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 1.0452738     |\n",
      "| policy_loss        | -0.0029758231 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 16.6          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 70047064.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002944861   |\n",
      "| clipfrac           | 0.0234375     |\n",
      "| ep_len_mean        | 287           |\n",
      "| ep_reward_mean     | -1.6e+05      |\n",
      "| explained_variance | 0.00459       |\n",
      "| fps                | 244           |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 1.0619024     |\n",
      "| policy_loss        | -0.0061888695 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 17.2          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 2947.1143     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0088657765 |\n",
      "| clipfrac           | 0.11328125   |\n",
      "| ep_len_mean        | 287          |\n",
      "| ep_reward_mean     | -1.6e+05     |\n",
      "| explained_variance | 0.000711     |\n",
      "| fps                | 231          |\n",
      "| n_updates          | 27           |\n",
      "| policy_entropy     | 1.2180355    |\n",
      "| policy_loss        | 0.0012814989 |\n",
      "| serial_timesteps   | 3456         |\n",
      "| time_elapsed       | 17.7         |\n",
      "| total_timesteps    | 3456         |\n",
      "| value_loss         | 34386920.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002420454   |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| ep_len_mean        | 287           |\n",
      "| ep_reward_mean     | -1.6e+05      |\n",
      "| explained_variance | 0.000504      |\n",
      "| fps                | 166           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 1.228591      |\n",
      "| policy_loss        | -0.0025431649 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 18.2          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 113406270.0   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -274024.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0012553644 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 307          |\n",
      "| ep_reward_mean     | -1.7e+05     |\n",
      "| explained_variance | 9.54e-07     |\n",
      "| fps                | 249          |\n",
      "| n_updates          | 29           |\n",
      "| policy_entropy     | 1.277576     |\n",
      "| policy_loss        | 0.0013867217 |\n",
      "| serial_timesteps   | 3712         |\n",
      "| time_elapsed       | 19           |\n",
      "| total_timesteps    | 3712         |\n",
      "| value_loss         | 86235070.0   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011313085 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 307          |\n",
      "| ep_reward_mean     | -1.7e+05     |\n",
      "| explained_variance | 0.0798       |\n",
      "| fps                | 167          |\n",
      "| n_updates          | 30           |\n",
      "| policy_entropy     | 1.2903904    |\n",
      "| policy_loss        | -0.003915048 |\n",
      "| serial_timesteps   | 3840         |\n",
      "| time_elapsed       | 19.5         |\n",
      "| total_timesteps    | 3840         |\n",
      "| value_loss         | 4606.461     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0036739986  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 307           |\n",
      "| ep_reward_mean     | -1.7e+05      |\n",
      "| explained_variance | 0.000649      |\n",
      "| fps                | 185           |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 1.2864646     |\n",
      "| policy_loss        | -0.0057934127 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 20.3          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 102197520.0   |\n",
      "--------------------------------------\n",
      "Num timesteps: 4000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -169861.17\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016689879  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 307           |\n",
      "| ep_reward_mean     | -1.7e+05      |\n",
      "| explained_variance | 2.13e-05      |\n",
      "| fps                | 173           |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 1.3241904     |\n",
      "| policy_loss        | -0.0013676247 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 21            |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 113316200.0   |\n",
      "--------------------------------------\n",
      "Reward -337858.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006573982  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 323           |\n",
      "| ep_reward_mean     | -1.83e+05     |\n",
      "| explained_variance | -2.38e-07     |\n",
      "| fps                | 160           |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 1.2942773     |\n",
      "| policy_loss        | -0.0024937862 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 21.7          |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 86178870.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038048875 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 323           |\n",
      "| ep_reward_mean     | -1.83e+05     |\n",
      "| explained_variance | 0.0902        |\n",
      "| fps                | 164           |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 1.2830719     |\n",
      "| policy_loss        | -0.0036113602 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 22.5          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 5273.4185     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0027790559 |\n",
      "| clipfrac           | 0.01953125   |\n",
      "| ep_len_mean        | 323          |\n",
      "| ep_reward_mean     | -1.83e+05    |\n",
      "| explained_variance | 0.000921     |\n",
      "| fps                | 159          |\n",
      "| n_updates          | 35           |\n",
      "| policy_entropy     | 1.2733823    |\n",
      "| policy_loss        | 0.005601202  |\n",
      "| serial_timesteps   | 4480         |\n",
      "| time_elapsed       | 23.3         |\n",
      "| total_timesteps    | 4480         |\n",
      "| value_loss         | 109784340.0  |\n",
      "-------------------------------------\n",
      "Reward -215524.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013604477 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 327          |\n",
      "| ep_reward_mean     | -1.85e+05    |\n",
      "| explained_variance | 2.8e-06      |\n",
      "| fps                | 162          |\n",
      "| n_updates          | 36           |\n",
      "| policy_entropy     | 1.3193932    |\n",
      "| policy_loss        | -0.002037616 |\n",
      "| serial_timesteps   | 4608         |\n",
      "| time_elapsed       | 24.1         |\n",
      "| total_timesteps    | 4608         |\n",
      "| value_loss         | 81735910.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.772488e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 327           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | 0.00358       |\n",
      "| fps                | 221           |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 1.2946241     |\n",
      "| policy_loss        | 0.00014347746 |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 24.9          |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 729814.3      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.117766e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 327            |\n",
      "| ep_reward_mean     | -1.85e+05      |\n",
      "| explained_variance | 0.000932       |\n",
      "| fps                | 297            |\n",
      "| n_updates          | 38             |\n",
      "| policy_entropy     | 1.2348626      |\n",
      "| policy_loss        | -0.00029340503 |\n",
      "| serial_timesteps   | 4864           |\n",
      "| time_elapsed       | 25.5           |\n",
      "| total_timesteps    | 4864           |\n",
      "| value_loss         | 113280930.0    |\n",
      "---------------------------------------\n",
      "Reward -184800.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00067876186 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 328           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | -4.53e-06     |\n",
      "| fps                | 307           |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 1.2678677     |\n",
      "| policy_loss        | 0.006924567   |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 25.9          |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 34990840.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 5000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -185301.07\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010155956 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| ep_len_mean        | 328          |\n",
      "| ep_reward_mean     | -1.85e+05    |\n",
      "| explained_variance | 0.000811     |\n",
      "| fps                | 320          |\n",
      "| n_updates          | 40           |\n",
      "| policy_entropy     | 1.1909388    |\n",
      "| policy_loss        | -0.004094166 |\n",
      "| serial_timesteps   | 5120         |\n",
      "| time_elapsed       | 26.3         |\n",
      "| total_timesteps    | 5120         |\n",
      "| value_loss         | 31215092.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004445249   |\n",
      "| clipfrac           | 0.03125       |\n",
      "| ep_len_mean        | 328           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | 0.000367      |\n",
      "| fps                | 320           |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 1.1421646     |\n",
      "| policy_loss        | -0.0014378141 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 26.7          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 113209224.0   |\n",
      "--------------------------------------\n",
      "Reward -177716.0\n",
      "--------------------------------------\n",
      "| approxkl           | 9.30086e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 329           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | -5.25e-05     |\n",
      "| fps                | 290           |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 1.0984626     |\n",
      "| policy_loss        | -0.0010881792 |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 27.1          |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 772908.94     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0040592942  |\n",
      "| clipfrac           | 0.052734375   |\n",
      "| ep_len_mean        | 329           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | 0.000521      |\n",
      "| fps                | 240           |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 1.0123708     |\n",
      "| policy_loss        | -0.0036406517 |\n",
      "| serial_timesteps   | 5504          |\n",
      "| time_elapsed       | 27.6          |\n",
      "| total_timesteps    | 5504          |\n",
      "| value_loss         | 52191956.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004367903   |\n",
      "| clipfrac           | 0.029296875   |\n",
      "| ep_len_mean        | 329           |\n",
      "| ep_reward_mean     | -1.85e+05     |\n",
      "| explained_variance | 0.000356      |\n",
      "| fps                | 310           |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 1.2452983     |\n",
      "| policy_loss        | -0.0030184295 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 28.1          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 113316970.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006818105 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 329          |\n",
      "| ep_reward_mean     | -1.85e+05    |\n",
      "| explained_variance | 1.79e-06     |\n",
      "| fps                | 237          |\n",
      "| n_updates          | 45           |\n",
      "| policy_entropy     | 1.3116927    |\n",
      "| policy_loss        | -0.003167201 |\n",
      "| serial_timesteps   | 5760         |\n",
      "| time_elapsed       | 28.5         |\n",
      "| total_timesteps    | 5760         |\n",
      "| value_loss         | 113246696.0  |\n",
      "-------------------------------------\n",
      "Reward -386292.0\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00053014874  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 343            |\n",
      "| ep_reward_mean     | -1.97e+05      |\n",
      "| explained_variance | -2.98e-06      |\n",
      "| fps                | 218            |\n",
      "| n_updates          | 46             |\n",
      "| policy_entropy     | 1.3208854      |\n",
      "| policy_loss        | -0.00015804253 |\n",
      "| serial_timesteps   | 5888           |\n",
      "| time_elapsed       | 29.1           |\n",
      "| total_timesteps    | 5888           |\n",
      "| value_loss         | 51617996.0     |\n",
      "---------------------------------------\n",
      "Num timesteps: 6000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -196795.53\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7640115e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 343           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 0.000648      |\n",
      "| fps                | 277           |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 1.2999487     |\n",
      "| policy_loss        | 0.00045723584 |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 29.7          |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 31192722.0    |\n",
      "--------------------------------------\n",
      "Reward -166826.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037529506 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -1.95e+05     |\n",
      "| explained_variance | 0.000286      |\n",
      "| fps                | 310           |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 1.313944      |\n",
      "| policy_loss        | -0.002881428  |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 30.1          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 111006680.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002618354 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 341          |\n",
      "| ep_reward_mean     | -1.95e+05    |\n",
      "| explained_variance | 0.00275      |\n",
      "| fps                | 274          |\n",
      "| n_updates          | 49           |\n",
      "| policy_entropy     | 1.3331558    |\n",
      "| policy_loss        | 0.0024647538 |\n",
      "| serial_timesteps   | 6272         |\n",
      "| time_elapsed       | 30.5         |\n",
      "| total_timesteps    | 6272         |\n",
      "| value_loss         | 1040156.94   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.841387e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 341          |\n",
      "| ep_reward_mean     | -1.95e+05    |\n",
      "| explained_variance | 0.000862     |\n",
      "| fps                | 327          |\n",
      "| n_updates          | 50           |\n",
      "| policy_entropy     | 1.3137941    |\n",
      "| policy_loss        | -0.000491604 |\n",
      "| serial_timesteps   | 6400         |\n",
      "| time_elapsed       | 31           |\n",
      "| total_timesteps    | 6400         |\n",
      "| value_loss         | 113209720.0  |\n",
      "-------------------------------------\n",
      "Reward -206666.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017405924 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | -4.05e-06     |\n",
      "| fps                | 333           |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 1.3327159     |\n",
      "| policy_loss        | 0.00020192075 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 31.4          |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 56872690.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008470369  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000666      |\n",
      "| fps                | 338           |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 1.3065553     |\n",
      "| policy_loss        | -0.0031714544 |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 31.8          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 35322950.0    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0016965406 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 341          |\n",
      "| ep_reward_mean     | -1.96e+05    |\n",
      "| explained_variance | 0.000352     |\n",
      "| fps                | 275          |\n",
      "| n_updates          | 53           |\n",
      "| policy_entropy     | 1.3582036    |\n",
      "| policy_loss        | 8.103671e-06 |\n",
      "| serial_timesteps   | 6784         |\n",
      "| time_elapsed       | 32.2         |\n",
      "| total_timesteps    | 6784         |\n",
      "| value_loss         | 113135600.0  |\n",
      "-------------------------------------\n",
      "Reward -230448.0\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2935981e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -1.98e+05     |\n",
      "| explained_variance | -1.54e-05     |\n",
      "| fps                | 304           |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 1.3661078     |\n",
      "| policy_loss        | 0.00018845679 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 32.6          |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 37976290.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 7000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -197623.20\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008229809  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -1.98e+05     |\n",
      "| explained_variance | 0.00044       |\n",
      "| fps                | 296           |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 1.3599824     |\n",
      "| policy_loss        | -0.0062980233 |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 33.1          |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 59587384.0    |\n",
      "--------------------------------------\n",
      "Reward -171870.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0041566314 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 340          |\n",
      "| ep_reward_mean     | -1.96e+05    |\n",
      "| explained_variance | 5.04e-05     |\n",
      "| fps                | 320          |\n",
      "| n_updates          | 56           |\n",
      "| policy_entropy     | 1.3173982    |\n",
      "| policy_loss        | 0.008717553  |\n",
      "| serial_timesteps   | 7168         |\n",
      "| time_elapsed       | 33.5         |\n",
      "| total_timesteps    | 7168         |\n",
      "| value_loss         | 87096700.0   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00028772798 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.00105       |\n",
      "| fps                | 282           |\n",
      "| n_updates          | 57            |\n",
      "| policy_entropy     | 1.2659098     |\n",
      "| policy_loss        | 0.004088833   |\n",
      "| serial_timesteps   | 7296          |\n",
      "| time_elapsed       | 33.9          |\n",
      "| total_timesteps    | 7296          |\n",
      "| value_loss         | 9933698.0     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000102771795 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 340            |\n",
      "| ep_reward_mean     | -1.96e+05      |\n",
      "| explained_variance | 0.000657       |\n",
      "| fps                | 391            |\n",
      "| n_updates          | 58             |\n",
      "| policy_entropy     | 1.2455834      |\n",
      "| policy_loss        | -0.0002505707  |\n",
      "| serial_timesteps   | 7424           |\n",
      "| time_elapsed       | 34.3           |\n",
      "| total_timesteps    | 7424           |\n",
      "| value_loss         | 113174536.0    |\n",
      "---------------------------------------\n",
      "Reward -201632.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004871333 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 340          |\n",
      "| ep_reward_mean     | -1.97e+05    |\n",
      "| explained_variance | -3.16e-05    |\n",
      "| fps                | 413          |\n",
      "| n_updates          | 59           |\n",
      "| policy_entropy     | 1.2590253    |\n",
      "| policy_loss        | 0.0010629753 |\n",
      "| serial_timesteps   | 7552         |\n",
      "| time_elapsed       | 34.7         |\n",
      "| total_timesteps    | 7552         |\n",
      "| value_loss         | 35909880.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0025909708  |\n",
      "| clipfrac           | 0.017578125   |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 0.000332      |\n",
      "| fps                | 452           |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 1.1698782     |\n",
      "| policy_loss        | -0.0068957955 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 35            |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 69272130.0    |\n",
      "--------------------------------------\n",
      "Reward -202680.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004303229   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 4.3e-05       |\n",
      "| fps                | 398           |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 1.3402883     |\n",
      "| policy_loss        | -0.0017563971 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 35.3          |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 110923890.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00064151204 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 0.11          |\n",
      "| fps                | 324           |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 1.3590726     |\n",
      "| policy_loss        | -0.0060638217 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 35.6          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 5980.051      |\n",
      "--------------------------------------\n",
      "Num timesteps: 8000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -197028.09\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0023138172 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.97e+05    |\n",
      "| explained_variance | 0.000881     |\n",
      "| fps                | 255          |\n",
      "| n_updates          | 63           |\n",
      "| policy_entropy     | 1.3721929    |\n",
      "| policy_loss        | -0.007748806 |\n",
      "| serial_timesteps   | 8064         |\n",
      "| time_elapsed       | 36           |\n",
      "| total_timesteps    | 8064         |\n",
      "| value_loss         | 112426530.0  |\n",
      "-------------------------------------\n",
      "Reward -157896.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028581067 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 338           |\n",
      "| ep_reward_mean     | -1.95e+05     |\n",
      "| explained_variance | -7.09e-05     |\n",
      "| fps                | 404           |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 1.3823825     |\n",
      "| policy_loss        | -0.0010667231 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 36.5          |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 16761669.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.418373e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 338           |\n",
      "| ep_reward_mean     | -1.95e+05     |\n",
      "| explained_variance | 0.000313      |\n",
      "| fps                | 406           |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 1.3841004     |\n",
      "| policy_loss        | -0.0003734352 |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 36.8          |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 79979000.0    |\n",
      "--------------------------------------\n",
      "Reward -201574.0\n",
      "--------------------------------------\n",
      "| approxkl           | 6.6714536e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 337           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 2.78e-05      |\n",
      "| fps                | 328           |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 1.3844559     |\n",
      "| policy_loss        | -0.0013733659 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 37.1          |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 98935990.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.6678397e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 337            |\n",
      "| ep_reward_mean     | -1.96e+05      |\n",
      "| explained_variance | 0.00525        |\n",
      "| fps                | 327            |\n",
      "| n_updates          | 67             |\n",
      "| policy_entropy     | 1.3842639      |\n",
      "| policy_loss        | 0.000102357415 |\n",
      "| serial_timesteps   | 8576           |\n",
      "| time_elapsed       | 37.5           |\n",
      "| total_timesteps    | 8576           |\n",
      "| value_loss         | 269303.16      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007081472  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 337           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000993      |\n",
      "| fps                | 338           |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 1.3815048     |\n",
      "| policy_loss        | -0.0074033635 |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 37.9          |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 113155190.0   |\n",
      "--------------------------------------\n",
      "Reward -204662.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0025977888 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 338          |\n",
      "| ep_reward_mean     | -1.96e+05    |\n",
      "| explained_variance | 2.98e-07     |\n",
      "| fps                | 233          |\n",
      "| n_updates          | 69           |\n",
      "| policy_entropy     | 1.378145     |\n",
      "| policy_loss        | 0.0026988934 |\n",
      "| serial_timesteps   | 8832         |\n",
      "| time_elapsed       | 38.3         |\n",
      "| total_timesteps    | 8832         |\n",
      "| value_loss         | 58016104.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037139343 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 338           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000649      |\n",
      "| fps                | 275           |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 1.32997       |\n",
      "| policy_loss        | 0.0012544978  |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 38.8          |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 33297728.0    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 9000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -196106.85\n",
      "--------------------------------------\n",
      "| approxkl           | 9.5855656e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 338           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000471      |\n",
      "| fps                | 255           |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 1.3665723     |\n",
      "| policy_loss        | -0.0007482718 |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 39.3          |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 113252970.0   |\n",
      "--------------------------------------\n",
      "Reward -229572.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019973316 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | -6.79e-06     |\n",
      "| fps                | 327           |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 1.3755136     |\n",
      "| policy_loss        | -0.0014909705 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 39.8          |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 39033290.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00025861055 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 0.000614      |\n",
      "| fps                | 272           |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 1.347776      |\n",
      "| policy_loss        | -0.001393503  |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 40.2          |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 35387730.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00026236137  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 339            |\n",
      "| ep_reward_mean     | -1.97e+05      |\n",
      "| explained_variance | 0.000428       |\n",
      "| fps                | 248            |\n",
      "| n_updates          | 74             |\n",
      "| policy_entropy     | 1.3812741      |\n",
      "| policy_loss        | -0.00023533101 |\n",
      "| serial_timesteps   | 9472           |\n",
      "| time_elapsed       | 40.7           |\n",
      "| total_timesteps    | 9472           |\n",
      "| value_loss         | 113258100.0    |\n",
      "---------------------------------------\n",
      "Reward -269234.0\n",
      "--------------------------------------\n",
      "| approxkl           | 3.2844786e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | -7.15e-07     |\n",
      "| fps                | 267           |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 1.3822227     |\n",
      "| policy_loss        | 0.0013596443  |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 41.2          |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 79514690.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.0246418e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 342            |\n",
      "| ep_reward_mean     | -2e+05         |\n",
      "| explained_variance | 0.000826       |\n",
      "| fps                | 252            |\n",
      "| n_updates          | 76             |\n",
      "| policy_entropy     | 1.3702339      |\n",
      "| policy_loss        | -1.9982399e-05 |\n",
      "| serial_timesteps   | 9728           |\n",
      "| time_elapsed       | 41.7           |\n",
      "| total_timesteps    | 9728           |\n",
      "| value_loss         | 12366675.0     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013572231 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.000622      |\n",
      "| fps                | 288           |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 1.3767076     |\n",
      "| policy_loss        | -0.00171886   |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 42.2          |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 113189790.0   |\n",
      "--------------------------------------\n",
      "Reward -200680.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000379798   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | -2.63e-05     |\n",
      "| fps                | 248           |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 1.375242      |\n",
      "| policy_loss        | -0.0042082155 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 42.6          |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 31875926.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 10000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -200043.59\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033828366 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 342           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.000317      |\n",
      "| fps                | 276           |\n",
      "| n_updates          | 79            |\n",
      "| policy_entropy     | 1.3437954     |\n",
      "| policy_loss        | -0.0016699092 |\n",
      "| serial_timesteps   | 10112         |\n",
      "| time_elapsed       | 43.1          |\n",
      "| total_timesteps    | 10112         |\n",
      "| value_loss         | 75770810.0    |\n",
      "--------------------------------------\n",
      "Reward -186872.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037317074 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 2.27e-05      |\n",
      "| fps                | 280           |\n",
      "| n_updates          | 80            |\n",
      "| policy_entropy     | 1.3671262     |\n",
      "| policy_loss        | -0.0011774931 |\n",
      "| serial_timesteps   | 10240         |\n",
      "| time_elapsed       | 43.6          |\n",
      "| total_timesteps    | 10240         |\n",
      "| value_loss         | 87088190.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.1972522e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.00136       |\n",
      "| fps                | 264           |\n",
      "| n_updates          | 81            |\n",
      "| policy_entropy     | 1.3533278     |\n",
      "| policy_loss        | -0.0010738357 |\n",
      "| serial_timesteps   | 10368         |\n",
      "| time_elapsed       | 44.1          |\n",
      "| total_timesteps    | 10368         |\n",
      "| value_loss         | 3755106.8     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00017347993  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 341            |\n",
      "| ep_reward_mean     | -2e+05         |\n",
      "| explained_variance | 0.000702       |\n",
      "| fps                | 239            |\n",
      "| n_updates          | 82             |\n",
      "| policy_entropy     | 1.3406488      |\n",
      "| policy_loss        | -0.00051080645 |\n",
      "| serial_timesteps   | 10496          |\n",
      "| time_elapsed       | 44.6           |\n",
      "| total_timesteps    | 10496          |\n",
      "| value_loss         | 113122570.0    |\n",
      "---------------------------------------\n",
      "Reward -175844.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033352786 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | -2.6e-05      |\n",
      "| fps                | 325           |\n",
      "| n_updates          | 83            |\n",
      "| policy_entropy     | 1.3515383     |\n",
      "| policy_loss        | -0.0011495022 |\n",
      "| serial_timesteps   | 10624         |\n",
      "| time_elapsed       | 45.1          |\n",
      "| total_timesteps    | 10624         |\n",
      "| value_loss         | 19457524.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013584222 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | 0.000288      |\n",
      "| fps                | 360           |\n",
      "| n_updates          | 84            |\n",
      "| policy_entropy     | 1.3022305     |\n",
      "| policy_loss        | 0.00034210493 |\n",
      "| serial_timesteps   | 10752         |\n",
      "| time_elapsed       | 45.5          |\n",
      "| total_timesteps    | 10752         |\n",
      "| value_loss         | 67120450.0    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -193698.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016427157 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | 5.89e-05      |\n",
      "| fps                | 346           |\n",
      "| n_updates          | 85            |\n",
      "| policy_entropy     | 1.338162      |\n",
      "| policy_loss        | -0.000736973  |\n",
      "| serial_timesteps   | 10880         |\n",
      "| time_elapsed       | 45.8          |\n",
      "| total_timesteps    | 10880         |\n",
      "| value_loss         | 103317540.0   |\n",
      "--------------------------------------\n",
      "Num timesteps: 11000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -198771.19\n",
      "--------------------------------------\n",
      "| approxkl           | 3.1753392e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | 0.00151       |\n",
      "| fps                | 337           |\n",
      "| n_updates          | 86            |\n",
      "| policy_entropy     | 1.312504      |\n",
      "| policy_loss        | -0.0005984657 |\n",
      "| serial_timesteps   | 11008         |\n",
      "| time_elapsed       | 46.2          |\n",
      "| total_timesteps    | 11008         |\n",
      "| value_loss         | 3206036.5     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004709672 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 340          |\n",
      "| ep_reward_mean     | -1.99e+05    |\n",
      "| explained_variance | 0.000763     |\n",
      "| fps                | 433          |\n",
      "| n_updates          | 87           |\n",
      "| policy_entropy     | 1.2969408    |\n",
      "| policy_loss        | -0.002617201 |\n",
      "| serial_timesteps   | 11136        |\n",
      "| time_elapsed       | 46.6         |\n",
      "| total_timesteps    | 11136        |\n",
      "| value_loss         | 113150080.0  |\n",
      "-------------------------------------\n",
      "Reward -170896.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0022418876 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.98e+05    |\n",
      "| explained_variance | -0.000141    |\n",
      "| fps                | 421          |\n",
      "| n_updates          | 88           |\n",
      "| policy_entropy     | 1.282556     |\n",
      "| policy_loss        | 0.004107901  |\n",
      "| serial_timesteps   | 11264        |\n",
      "| time_elapsed       | 46.9         |\n",
      "| total_timesteps    | 11264        |\n",
      "| value_loss         | 15900023.0   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0023905062 |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.98e+05    |\n",
      "| explained_variance | 0.000149     |\n",
      "| fps                | 332          |\n",
      "| n_updates          | 89           |\n",
      "| policy_entropy     | 1.1785698    |\n",
      "| policy_loss        | -0.006064616 |\n",
      "| serial_timesteps   | 11392        |\n",
      "| time_elapsed       | 47.2         |\n",
      "| total_timesteps    | 11392        |\n",
      "| value_loss         | 78985250.0   |\n",
      "-------------------------------------\n",
      "Reward -210696.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0066309343 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.98e+05    |\n",
      "| explained_variance | 6.12e-05     |\n",
      "| fps                | 316          |\n",
      "| n_updates          | 90           |\n",
      "| policy_entropy     | 1.150543     |\n",
      "| policy_loss        | 0.0041732746 |\n",
      "| serial_timesteps   | 11520        |\n",
      "| time_elapsed       | 47.6         |\n",
      "| total_timesteps    | 11520        |\n",
      "| value_loss         | 109998530.0  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0017681911  |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -1.98e+05     |\n",
      "| explained_variance | 0.0995        |\n",
      "| fps                | 367           |\n",
      "| n_updates          | 91            |\n",
      "| policy_entropy     | 1.0740739     |\n",
      "| policy_loss        | -0.0046049817 |\n",
      "| serial_timesteps   | 11648         |\n",
      "| time_elapsed       | 48            |\n",
      "| total_timesteps    | 11648         |\n",
      "| value_loss         | 5122.547      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0061611654 |\n",
      "| clipfrac           | 0.056640625  |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.98e+05    |\n",
      "| explained_variance | 0.000636     |\n",
      "| fps                | 378          |\n",
      "| n_updates          | 92           |\n",
      "| policy_entropy     | 1.0137188    |\n",
      "| policy_loss        | 0.014203706  |\n",
      "| serial_timesteps   | 11776        |\n",
      "| time_elapsed       | 48.3         |\n",
      "| total_timesteps    | 11776        |\n",
      "| value_loss         | 105763830.0  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005256813  |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 339          |\n",
      "| ep_reward_mean     | -1.98e+05    |\n",
      "| explained_variance | 6.76e-05     |\n",
      "| fps                | 306          |\n",
      "| n_updates          | 93           |\n",
      "| policy_entropy     | 1.1083654    |\n",
      "| policy_loss        | 0.0022663025 |\n",
      "| serial_timesteps   | 11904        |\n",
      "| time_elapsed       | 48.7         |\n",
      "| total_timesteps    | 11904        |\n",
      "| value_loss         | 113252090.0  |\n",
      "-------------------------------------\n",
      "Num timesteps: 12000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -198360.88\n",
      "Reward -335930.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008886878  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 343           |\n",
      "| ep_reward_mean     | -2.02e+05     |\n",
      "| explained_variance | -1.07e-06     |\n",
      "| fps                | 259           |\n",
      "| n_updates          | 94            |\n",
      "| policy_entropy     | 1.0380889     |\n",
      "| policy_loss        | -0.0018843417 |\n",
      "| serial_timesteps   | 12032         |\n",
      "| time_elapsed       | 49.1          |\n",
      "| total_timesteps    | 12032         |\n",
      "| value_loss         | 79589544.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003923793  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 343           |\n",
      "| ep_reward_mean     | -2.02e+05     |\n",
      "| explained_variance | 0.112         |\n",
      "| fps                | 342           |\n",
      "| n_updates          | 95            |\n",
      "| policy_entropy     | 0.99040276    |\n",
      "| policy_loss        | -0.0012355979 |\n",
      "| serial_timesteps   | 12160         |\n",
      "| time_elapsed       | 49.6          |\n",
      "| total_timesteps    | 12160         |\n",
      "| value_loss         | 4634.3657     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.011135741  |\n",
      "| clipfrac           | 0.171875     |\n",
      "| ep_len_mean        | 343          |\n",
      "| ep_reward_mean     | -2.02e+05    |\n",
      "| explained_variance | 0.000906     |\n",
      "| fps                | 353          |\n",
      "| n_updates          | 96           |\n",
      "| policy_entropy     | 0.9574429    |\n",
      "| policy_loss        | -0.012496522 |\n",
      "| serial_timesteps   | 12288        |\n",
      "| time_elapsed       | 50           |\n",
      "| total_timesteps    | 12288        |\n",
      "| value_loss         | 111151470.0  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.002801683 |\n",
      "| clipfrac           | 0.009765625 |\n",
      "| ep_len_mean        | 343         |\n",
      "| ep_reward_mean     | -2.02e+05   |\n",
      "| explained_variance | 2.82e-05    |\n",
      "| fps                | 267         |\n",
      "| n_updates          | 97          |\n",
      "| policy_entropy     | 1.1427872   |\n",
      "| policy_loss        | 0.002793288 |\n",
      "| serial_timesteps   | 12416       |\n",
      "| time_elapsed       | 50.3        |\n",
      "| total_timesteps    | 12416       |\n",
      "| value_loss         | 113201250.0 |\n",
      "------------------------------------\n",
      "Reward -373536.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013155314 |\n",
      "| clipfrac           | 0.00390625   |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.07e+05    |\n",
      "| explained_variance | 4.77e-07     |\n",
      "| fps                | 325          |\n",
      "| n_updates          | 98           |\n",
      "| policy_entropy     | 1.1394342    |\n",
      "| policy_loss        | -0.006747759 |\n",
      "| serial_timesteps   | 12544        |\n",
      "| time_elapsed       | 50.8         |\n",
      "| total_timesteps    | 12544        |\n",
      "| value_loss         | 113181144.0  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0009854988 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.07e+05    |\n",
      "| explained_variance | 0.0714       |\n",
      "| fps                | 259          |\n",
      "| n_updates          | 99           |\n",
      "| policy_entropy     | 1.1254404    |\n",
      "| policy_loss        | 0.007821808  |\n",
      "| serial_timesteps   | 12672        |\n",
      "| time_elapsed       | 51.2         |\n",
      "| total_timesteps    | 12672        |\n",
      "| value_loss         | 5039.413     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009526185  |\n",
      "| clipfrac           | 0.091796875  |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.07e+05    |\n",
      "| explained_variance | 0.000253     |\n",
      "| fps                | 162          |\n",
      "| n_updates          | 100          |\n",
      "| policy_entropy     | 1.1057489    |\n",
      "| policy_loss        | -0.010756826 |\n",
      "| serial_timesteps   | 12800        |\n",
      "| time_elapsed       | 51.7         |\n",
      "| total_timesteps    | 12800        |\n",
      "| value_loss         | 90842136.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009492707  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 7.58e-05      |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 101           |\n",
      "| policy_entropy     | 1.2226019     |\n",
      "| policy_loss        | -0.0034533762 |\n",
      "| serial_timesteps   | 12928         |\n",
      "| time_elapsed       | 52.5          |\n",
      "| total_timesteps    | 12928         |\n",
      "| value_loss         | 113162750.0   |\n",
      "--------------------------------------\n",
      "Num timesteps: 13000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -207103.78\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0022581136  |\n",
      "| clipfrac           | 0.03515625    |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 1.13e-06      |\n",
      "| fps                | 289           |\n",
      "| n_updates          | 102           |\n",
      "| policy_entropy     | 1.2697364     |\n",
      "| policy_loss        | -0.0014706383 |\n",
      "| serial_timesteps   | 13056         |\n",
      "| time_elapsed       | 53.2          |\n",
      "| total_timesteps    | 13056         |\n",
      "| value_loss         | 113054180.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018605118 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | -3.58e-07     |\n",
      "| fps                | 240           |\n",
      "| n_updates          | 103           |\n",
      "| policy_entropy     | 1.2874836     |\n",
      "| policy_loss        | -5.177816e-05 |\n",
      "| serial_timesteps   | 13184         |\n",
      "| time_elapsed       | 53.6          |\n",
      "| total_timesteps    | 13184         |\n",
      "| value_loss         | 113118584.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012640035  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | -1.65e-05     |\n",
      "| fps                | 165           |\n",
      "| n_updates          | 104           |\n",
      "| policy_entropy     | 1.2533325     |\n",
      "| policy_loss        | -0.0007874451 |\n",
      "| serial_timesteps   | 13312         |\n",
      "| time_elapsed       | 54.2          |\n",
      "| total_timesteps    | 13312         |\n",
      "| value_loss         | 113092360.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007955216 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.07e+05    |\n",
      "| explained_variance | -0.000115    |\n",
      "| fps                | 241          |\n",
      "| n_updates          | 105          |\n",
      "| policy_entropy     | 1.2383451    |\n",
      "| policy_loss        | 0.0026188623 |\n",
      "| serial_timesteps   | 13440        |\n",
      "| time_elapsed       | 54.9         |\n",
      "| total_timesteps    | 13440        |\n",
      "| value_loss         | 113092190.0  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0042713713  |\n",
      "| clipfrac           | 0.025390625   |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 0.000113      |\n",
      "| fps                | 331           |\n",
      "| n_updates          | 106           |\n",
      "| policy_entropy     | 1.1732595     |\n",
      "| policy_loss        | -0.0059673875 |\n",
      "| serial_timesteps   | 13568         |\n",
      "| time_elapsed       | 55.5          |\n",
      "| total_timesteps    | 13568         |\n",
      "| value_loss         | 113050070.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016577827  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 2.47e-05      |\n",
      "| fps                | 301           |\n",
      "| n_updates          | 107           |\n",
      "| policy_entropy     | 1.1319014     |\n",
      "| policy_loss        | -0.0020074612 |\n",
      "| serial_timesteps   | 13696         |\n",
      "| time_elapsed       | 55.9          |\n",
      "| total_timesteps    | 13696         |\n",
      "| value_loss         | 113009464.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0025037425  |\n",
      "| clipfrac           | 0.05078125    |\n",
      "| ep_len_mean        | 348           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 7.15e-07      |\n",
      "| fps                | 230           |\n",
      "| n_updates          | 108           |\n",
      "| policy_entropy     | 1.1325604     |\n",
      "| policy_loss        | -0.0050298558 |\n",
      "| serial_timesteps   | 13824         |\n",
      "| time_elapsed       | 56.3          |\n",
      "| total_timesteps    | 13824         |\n",
      "| value_loss         | 112978800.0   |\n",
      "--------------------------------------\n",
      "Reward -1140744.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007479661  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 374           |\n",
      "| ep_reward_mean     | -2.32e+05     |\n",
      "| explained_variance | -3.59e-05     |\n",
      "| fps                | 206           |\n",
      "| n_updates          | 109           |\n",
      "| policy_entropy     | 1.2028797     |\n",
      "| policy_loss        | -0.0005552792 |\n",
      "| serial_timesteps   | 13952         |\n",
      "| time_elapsed       | 56.8          |\n",
      "| total_timesteps    | 13952         |\n",
      "| value_loss         | 9538588.0     |\n",
      "--------------------------------------\n",
      "Num timesteps: 14000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -232364.32\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00011593293 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 374           |\n",
      "| ep_reward_mean     | -2.32e+05     |\n",
      "| explained_variance | 6.85e-05      |\n",
      "| fps                | 246           |\n",
      "| n_updates          | 110           |\n",
      "| policy_entropy     | 1.072128      |\n",
      "| policy_loss        | -0.0005225715 |\n",
      "| serial_timesteps   | 14080         |\n",
      "| time_elapsed       | 57.5          |\n",
      "| total_timesteps    | 14080         |\n",
      "| value_loss         | 86240490.0    |\n",
      "--------------------------------------\n",
      "Reward -164714.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00057128386 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 372           |\n",
      "| ep_reward_mean     | -2.31e+05     |\n",
      "| explained_variance | 2.98e-06      |\n",
      "| fps                | 303           |\n",
      "| n_updates          | 111           |\n",
      "| policy_entropy     | 1.1781956     |\n",
      "| policy_loss        | 0.0031523737  |\n",
      "| serial_timesteps   | 14208         |\n",
      "| time_elapsed       | 58            |\n",
      "| total_timesteps    | 14208         |\n",
      "| value_loss         | 52551572.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0040971413  |\n",
      "| clipfrac           | 0.0390625     |\n",
      "| ep_len_mean        | 372           |\n",
      "| ep_reward_mean     | -2.31e+05     |\n",
      "| explained_variance | 9.61e-05      |\n",
      "| fps                | 213           |\n",
      "| n_updates          | 112           |\n",
      "| policy_entropy     | 0.9946613     |\n",
      "| policy_loss        | -0.0054266187 |\n",
      "| serial_timesteps   | 14336         |\n",
      "| time_elapsed       | 58.4          |\n",
      "| total_timesteps    | 14336         |\n",
      "| value_loss         | 42508624.0    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -168694.0\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0012060076   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 371            |\n",
      "| ep_reward_mean     | -2.29e+05      |\n",
      "| explained_variance | 3.86e-05       |\n",
      "| fps                | 346            |\n",
      "| n_updates          | 113            |\n",
      "| policy_entropy     | 1.0407814      |\n",
      "| policy_loss        | -0.00086430064 |\n",
      "| serial_timesteps   | 14464          |\n",
      "| time_elapsed       | 59             |\n",
      "| total_timesteps    | 14464          |\n",
      "| value_loss         | 100952310.0    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019044126 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 371           |\n",
      "| ep_reward_mean     | -2.29e+05     |\n",
      "| explained_variance | 0.000197      |\n",
      "| fps                | 282           |\n",
      "| n_updates          | 114           |\n",
      "| policy_entropy     | 0.8930107     |\n",
      "| policy_loss        | -0.0013197898 |\n",
      "| serial_timesteps   | 14592         |\n",
      "| time_elapsed       | 59.4          |\n",
      "| total_timesteps    | 14592         |\n",
      "| value_loss         | 13140111.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8257058e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 371           |\n",
      "| ep_reward_mean     | -2.29e+05     |\n",
      "| explained_variance | 0.000153      |\n",
      "| fps                | 294           |\n",
      "| n_updates          | 115           |\n",
      "| policy_entropy     | 0.9629546     |\n",
      "| policy_loss        | 0.00011420663 |\n",
      "| serial_timesteps   | 14720         |\n",
      "| time_elapsed       | 59.8          |\n",
      "| total_timesteps    | 14720         |\n",
      "| value_loss         | 112782500.0   |\n",
      "--------------------------------------\n",
      "Reward -151772.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005690392  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 368           |\n",
      "| ep_reward_mean     | -2.27e+05     |\n",
      "| explained_variance | 0.000293      |\n",
      "| fps                | 320           |\n",
      "| n_updates          | 116           |\n",
      "| policy_entropy     | 0.8971415     |\n",
      "| policy_loss        | 2.5103102e-05 |\n",
      "| serial_timesteps   | 14848         |\n",
      "| time_elapsed       | 60.3          |\n",
      "| total_timesteps    | 14848         |\n",
      "| value_loss         | 6915926.0     |\n",
      "--------------------------------------\n",
      "Reward -140870.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001971179  |\n",
      "| clipfrac           | 0.015625     |\n",
      "| ep_len_mean        | 365          |\n",
      "| ep_reward_mean     | -2.25e+05    |\n",
      "| explained_variance | 0.000176     |\n",
      "| fps                | 348          |\n",
      "| n_updates          | 117          |\n",
      "| policy_entropy     | 0.9418507    |\n",
      "| policy_loss        | -0.009581065 |\n",
      "| serial_timesteps   | 14976        |\n",
      "| time_elapsed       | 60.7         |\n",
      "| total_timesteps    | 14976        |\n",
      "| value_loss         | 111663710.0  |\n",
      "-------------------------------------\n",
      "Num timesteps: 15000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -225061.71\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0030319772 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| ep_len_mean        | 365          |\n",
      "| ep_reward_mean     | -2.25e+05    |\n",
      "| explained_variance | 0.0293       |\n",
      "| fps                | 348          |\n",
      "| n_updates          | 118          |\n",
      "| policy_entropy     | 1.048285     |\n",
      "| policy_loss        | 0.01098206   |\n",
      "| serial_timesteps   | 15104        |\n",
      "| time_elapsed       | 61           |\n",
      "| total_timesteps    | 15104        |\n",
      "| value_loss         | 7005.238     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0023929703  |\n",
      "| clipfrac           | 0.015625      |\n",
      "| ep_len_mean        | 365           |\n",
      "| ep_reward_mean     | -2.25e+05     |\n",
      "| explained_variance | 0.000285      |\n",
      "| fps                | 358           |\n",
      "| n_updates          | 119           |\n",
      "| policy_entropy     | 1.0072825     |\n",
      "| policy_loss        | -0.0041961083 |\n",
      "| serial_timesteps   | 15232         |\n",
      "| time_elapsed       | 61.4          |\n",
      "| total_timesteps    | 15232         |\n",
      "| value_loss         | 111372060.0   |\n",
      "--------------------------------------\n",
      "Reward -185628.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0008276236 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 364          |\n",
      "| ep_reward_mean     | -2.24e+05    |\n",
      "| explained_variance | -2.62e-06    |\n",
      "| fps                | 283          |\n",
      "| n_updates          | 120          |\n",
      "| policy_entropy     | 1.1656832    |\n",
      "| policy_loss        | 0.0033824334 |\n",
      "| serial_timesteps   | 15360        |\n",
      "| time_elapsed       | 61.8         |\n",
      "| total_timesteps    | 15360        |\n",
      "| value_loss         | 46264880.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006849052  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 364           |\n",
      "| ep_reward_mean     | -2.24e+05     |\n",
      "| explained_variance | 0.000154      |\n",
      "| fps                | 190           |\n",
      "| n_updates          | 121           |\n",
      "| policy_entropy     | 1.0864891     |\n",
      "| policy_loss        | 0.00040759228 |\n",
      "| serial_timesteps   | 15488         |\n",
      "| time_elapsed       | 62.2          |\n",
      "| total_timesteps    | 15488         |\n",
      "| value_loss         | 45605124.0    |\n",
      "--------------------------------------\n",
      "Reward -151828.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020503573 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 362           |\n",
      "| ep_reward_mean     | -2.22e+05     |\n",
      "| explained_variance | 5.13e-05      |\n",
      "| fps                | 238           |\n",
      "| n_updates          | 122           |\n",
      "| policy_entropy     | 1.1884583     |\n",
      "| policy_loss        | -0.0003988807 |\n",
      "| serial_timesteps   | 15616         |\n",
      "| time_elapsed       | 62.9          |\n",
      "| total_timesteps    | 15616         |\n",
      "| value_loss         | 79391496.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7755685e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 362           |\n",
      "| ep_reward_mean     | -2.22e+05     |\n",
      "| explained_variance | 0.000211      |\n",
      "| fps                | 253           |\n",
      "| n_updates          | 123           |\n",
      "| policy_entropy     | 1.1135887     |\n",
      "| policy_loss        | 0.0006365549  |\n",
      "| serial_timesteps   | 15744         |\n",
      "| time_elapsed       | 63.4          |\n",
      "| total_timesteps    | 15744         |\n",
      "| value_loss         | 18541584.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00025388133  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 362            |\n",
      "| ep_reward_mean     | -2.22e+05      |\n",
      "| explained_variance | 0.000288       |\n",
      "| fps                | 316            |\n",
      "| n_updates          | 124            |\n",
      "| policy_entropy     | 1.1655277      |\n",
      "| policy_loss        | -0.00069740857 |\n",
      "| serial_timesteps   | 15872          |\n",
      "| time_elapsed       | 64             |\n",
      "| total_timesteps    | 15872          |\n",
      "| value_loss         | 112994370.0    |\n",
      "---------------------------------------\n",
      "Reward -264038.0\n",
      "Num timesteps: 16000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -223455.09\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004331728 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 363          |\n",
      "| ep_reward_mean     | -2.23e+05    |\n",
      "| explained_variance | 1.49e-06     |\n",
      "| fps                | 229          |\n",
      "| n_updates          | 125          |\n",
      "| policy_entropy     | 1.2166605    |\n",
      "| policy_loss        | 0.0022252244 |\n",
      "| serial_timesteps   | 16000        |\n",
      "| time_elapsed       | 64.4         |\n",
      "| total_timesteps    | 16000        |\n",
      "| value_loss         | 92363590.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4171493e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 363           |\n",
      "| ep_reward_mean     | -2.23e+05     |\n",
      "| explained_variance | 0.0367        |\n",
      "| fps                | 255           |\n",
      "| n_updates          | 126           |\n",
      "| policy_entropy     | 1.207669      |\n",
      "| policy_loss        | 0.00011231832 |\n",
      "| serial_timesteps   | 16128         |\n",
      "| time_elapsed       | 64.9          |\n",
      "| total_timesteps    | 16128         |\n",
      "| value_loss         | 6120.059      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00014361365 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 363           |\n",
      "| ep_reward_mean     | -2.23e+05     |\n",
      "| explained_variance | 0.0003        |\n",
      "| fps                | 242           |\n",
      "| n_updates          | 127           |\n",
      "| policy_entropy     | 1.1380057     |\n",
      "| policy_loss        | -0.0009209052 |\n",
      "| serial_timesteps   | 16256         |\n",
      "| time_elapsed       | 65.4          |\n",
      "| total_timesteps    | 16256         |\n",
      "| value_loss         | 108874160.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005979317  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 363           |\n",
      "| ep_reward_mean     | -2.23e+05     |\n",
      "| explained_variance | 1.7e-05       |\n",
      "| fps                | 273           |\n",
      "| n_updates          | 128           |\n",
      "| policy_entropy     | 1.1918559     |\n",
      "| policy_loss        | -0.0032720538 |\n",
      "| serial_timesteps   | 16384         |\n",
      "| time_elapsed       | 66            |\n",
      "| total_timesteps    | 16384         |\n",
      "| value_loss         | 113125200.0   |\n",
      "--------------------------------------\n",
      "Reward -256110.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017733101 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 364          |\n",
      "| ep_reward_mean     | -2.24e+05    |\n",
      "| explained_variance | -0.000144    |\n",
      "| fps                | 199          |\n",
      "| n_updates          | 129          |\n",
      "| policy_entropy     | 1.1501733    |\n",
      "| policy_loss        | -0.001527401 |\n",
      "| serial_timesteps   | 16512        |\n",
      "| time_elapsed       | 66.4         |\n",
      "| total_timesteps    | 16512        |\n",
      "| value_loss         | 1874393.4    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014959542 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 364           |\n",
      "| ep_reward_mean     | -2.24e+05     |\n",
      "| explained_variance | 0.000191      |\n",
      "| fps                | 254           |\n",
      "| n_updates          | 130           |\n",
      "| policy_entropy     | 1.0650357     |\n",
      "| policy_loss        | 0.0002946864  |\n",
      "| serial_timesteps   | 16640         |\n",
      "| time_elapsed       | 67.1          |\n",
      "| total_timesteps    | 16640         |\n",
      "| value_loss         | 101695450.0   |\n",
      "--------------------------------------\n",
      "Reward -194470.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033419396 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 364           |\n",
      "| ep_reward_mean     | -2.24e+05     |\n",
      "| explained_variance | 2.38e-06      |\n",
      "| fps                | 208           |\n",
      "| n_updates          | 131           |\n",
      "| policy_entropy     | 1.1740276     |\n",
      "| policy_loss        | 0.0004696597  |\n",
      "| serial_timesteps   | 16768         |\n",
      "| time_elapsed       | 67.6          |\n",
      "| total_timesteps    | 16768         |\n",
      "| value_loss         | 68535700.0    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0001805794 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 364          |\n",
      "| ep_reward_mean     | -2.24e+05    |\n",
      "| explained_variance | 0.000153     |\n",
      "| fps                | 276          |\n",
      "| n_updates          | 132          |\n",
      "| policy_entropy     | 1.1118422    |\n",
      "| policy_loss        | -0.001975413 |\n",
      "| serial_timesteps   | 16896        |\n",
      "| time_elapsed       | 68.2         |\n",
      "| total_timesteps    | 16896        |\n",
      "| value_loss         | 31191398.0   |\n",
      "-------------------------------------\n",
      "Num timesteps: 17000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -223578.35\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010592106  |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| ep_len_mean        | 364           |\n",
      "| ep_reward_mean     | -2.24e+05     |\n",
      "| explained_variance | 0.000177      |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 133           |\n",
      "| policy_entropy     | 1.1463001     |\n",
      "| policy_loss        | -0.0037734336 |\n",
      "| serial_timesteps   | 17024         |\n",
      "| time_elapsed       | 68.7          |\n",
      "| total_timesteps    | 17024         |\n",
      "| value_loss         | 113015600.0   |\n",
      "--------------------------------------\n",
      "Reward -270952.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0058142897 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| ep_len_mean        | 364          |\n",
      "| ep_reward_mean     | -2.25e+05    |\n",
      "| explained_variance | -2.38e-07    |\n",
      "| fps                | 235          |\n",
      "| n_updates          | 134          |\n",
      "| policy_entropy     | 1.0327071    |\n",
      "| policy_loss        | -0.00735347  |\n",
      "| serial_timesteps   | 17152        |\n",
      "| time_elapsed       | 69.3         |\n",
      "| total_timesteps    | 17152        |\n",
      "| value_loss         | 85717520.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.252651e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 364           |\n",
      "| ep_reward_mean     | -2.25e+05     |\n",
      "| explained_variance | 0.000182      |\n",
      "| fps                | 237           |\n",
      "| n_updates          | 135           |\n",
      "| policy_entropy     | 0.8620461     |\n",
      "| policy_loss        | 0.00041613443 |\n",
      "| serial_timesteps   | 17280         |\n",
      "| time_elapsed       | 69.9          |\n",
      "| total_timesteps    | 17280         |\n",
      "| value_loss         | 26052276.0    |\n",
      "--------------------------------------\n",
      "Reward -139876.0\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00011923179  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 362            |\n",
      "| ep_reward_mean     | -2.23e+05      |\n",
      "| explained_variance | 9.58e-05       |\n",
      "| fps                | 267            |\n",
      "| n_updates          | 136            |\n",
      "| policy_entropy     | 0.99318886     |\n",
      "| policy_loss        | -0.00018889143 |\n",
      "| serial_timesteps   | 17408          |\n",
      "| time_elapsed       | 70.4           |\n",
      "| total_timesteps    | 17408          |\n",
      "| value_loss         | 86836080.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.06821735e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 362            |\n",
      "| ep_reward_mean     | -2.23e+05      |\n",
      "| explained_variance | 0.000205       |\n",
      "| fps                | 173            |\n",
      "| n_updates          | 137            |\n",
      "| policy_entropy     | 0.9070929      |\n",
      "| policy_loss        | 3.831857e-05   |\n",
      "| serial_timesteps   | 17536          |\n",
      "| time_elapsed       | 70.9           |\n",
      "| total_timesteps    | 17536          |\n",
      "| value_loss         | 30034908.0     |\n",
      "---------------------------------------\n",
      "Reward -140880.0\n",
      "--------------------------------------\n",
      "| approxkl           | 8.9217494e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 360           |\n",
      "| ep_reward_mean     | -2.21e+05     |\n",
      "| explained_variance | 9.85e-05      |\n",
      "| fps                | 191           |\n",
      "| n_updates          | 138           |\n",
      "| policy_entropy     | 1.0129145     |\n",
      "| policy_loss        | 0.00090361014 |\n",
      "| serial_timesteps   | 17664         |\n",
      "| time_elapsed       | 71.6          |\n",
      "| total_timesteps    | 17664         |\n",
      "| value_loss         | 83589820.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7653476e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 360           |\n",
      "| ep_reward_mean     | -2.21e+05     |\n",
      "| explained_variance | 0.000252      |\n",
      "| fps                | 274           |\n",
      "| n_updates          | 139           |\n",
      "| policy_entropy     | 0.95323783    |\n",
      "| policy_loss        | 0.00035132107 |\n",
      "| serial_timesteps   | 17792         |\n",
      "| time_elapsed       | 72.3          |\n",
      "| total_timesteps    | 17792         |\n",
      "| value_loss         | 26096872.0    |\n",
      "--------------------------------------\n",
      "Reward -152840.0\n",
      "--------------------------------------\n",
      "| approxkl           | 5.4995076e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 358           |\n",
      "| ep_reward_mean     | -2.2e+05      |\n",
      "| explained_variance | 0.000144      |\n",
      "| fps                | 167           |\n",
      "| n_updates          | 140           |\n",
      "| policy_entropy     | 1.0169233     |\n",
      "| policy_loss        | 2.09047e-06   |\n",
      "| serial_timesteps   | 17920         |\n",
      "| time_elapsed       | 72.8          |\n",
      "| total_timesteps    | 17920         |\n",
      "| value_loss         | 100935490.0   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 18000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -219863.04\n",
      "---------------------------------------\n",
      "| approxkl           | 2.7766423e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 358            |\n",
      "| ep_reward_mean     | -2.2e+05       |\n",
      "| explained_variance | 0.000641       |\n",
      "| fps                | 213            |\n",
      "| n_updates          | 141            |\n",
      "| policy_entropy     | 0.9844154      |\n",
      "| policy_loss        | -0.00020896673 |\n",
      "| serial_timesteps   | 18048          |\n",
      "| time_elapsed       | 73.6           |\n",
      "| total_timesteps    | 18048          |\n",
      "| value_loss         | 4320724.5      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 3.937073e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 358          |\n",
      "| ep_reward_mean     | -2.2e+05     |\n",
      "| explained_variance | 0.000515     |\n",
      "| fps                | 250          |\n",
      "| n_updates          | 142          |\n",
      "| policy_entropy     | 0.97857976   |\n",
      "| policy_loss        | 0.0001301408 |\n",
      "| serial_timesteps   | 18176        |\n",
      "| time_elapsed       | 74.2         |\n",
      "| total_timesteps    | 18176        |\n",
      "| value_loss         | 112833656.0  |\n",
      "-------------------------------------\n",
      "Reward -189476.0\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3402084e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 357           |\n",
      "| ep_reward_mean     | -2.19e+05     |\n",
      "| explained_variance | -5.73e-05     |\n",
      "| fps                | 271           |\n",
      "| n_updates          | 143           |\n",
      "| policy_entropy     | 1.0192757     |\n",
      "| policy_loss        | 0.0009867268  |\n",
      "| serial_timesteps   | 18304         |\n",
      "| time_elapsed       | 74.7          |\n",
      "| total_timesteps    | 18304         |\n",
      "| value_loss         | 31784748.0    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0032365625 |\n",
      "| clipfrac           | 0.029296875  |\n",
      "| ep_len_mean        | 357          |\n",
      "| ep_reward_mean     | -2.19e+05    |\n",
      "| explained_variance | 0.000144     |\n",
      "| fps                | 334          |\n",
      "| n_updates          | 144          |\n",
      "| policy_entropy     | 0.89760697   |\n",
      "| policy_loss        | -0.006012221 |\n",
      "| serial_timesteps   | 18432        |\n",
      "| time_elapsed       | 75.1         |\n",
      "| total_timesteps    | 18432        |\n",
      "| value_loss         | 79780290.0   |\n",
      "-------------------------------------\n",
      "Reward -172582.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0025731693  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 356           |\n",
      "| ep_reward_mean     | -2.18e+05     |\n",
      "| explained_variance | 7.81e-06      |\n",
      "| fps                | 199           |\n",
      "| n_updates          | 145           |\n",
      "| policy_entropy     | 0.8821721     |\n",
      "| policy_loss        | -0.0014717886 |\n",
      "| serial_timesteps   | 18560         |\n",
      "| time_elapsed       | 75.5          |\n",
      "| total_timesteps    | 18560         |\n",
      "| value_loss         | 67341300.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0002475282   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 356            |\n",
      "| ep_reward_mean     | -2.18e+05      |\n",
      "| explained_variance | 0.000221       |\n",
      "| fps                | 248            |\n",
      "| n_updates          | 146            |\n",
      "| policy_entropy     | 0.71563315     |\n",
      "| policy_loss        | -0.00070265634 |\n",
      "| serial_timesteps   | 18688          |\n",
      "| time_elapsed       | 76.2           |\n",
      "| total_timesteps    | 18688          |\n",
      "| value_loss         | 46581390.0     |\n",
      "---------------------------------------\n",
      "Reward -150710.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00072141376 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 354           |\n",
      "| ep_reward_mean     | -2.17e+05     |\n",
      "| explained_variance | 6.52e-05      |\n",
      "| fps                | 262           |\n",
      "| n_updates          | 147           |\n",
      "| policy_entropy     | 0.8528433     |\n",
      "| policy_loss        | 4.4923392e-05 |\n",
      "| serial_timesteps   | 18816         |\n",
      "| time_elapsed       | 76.7          |\n",
      "| total_timesteps    | 18816         |\n",
      "| value_loss         | 76950980.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00054571003 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 354           |\n",
      "| ep_reward_mean     | -2.17e+05     |\n",
      "| explained_variance | 0.000246      |\n",
      "| fps                | 262           |\n",
      "| n_updates          | 148           |\n",
      "| policy_entropy     | 0.73023593    |\n",
      "| policy_loss        | -0.0017378356 |\n",
      "| serial_timesteps   | 18944         |\n",
      "| time_elapsed       | 77.2          |\n",
      "| total_timesteps    | 18944         |\n",
      "| value_loss         | 42352636.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 19000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -217149.43\n",
      "Reward -140774.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0026632987  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 352           |\n",
      "| ep_reward_mean     | -2.16e+05     |\n",
      "| explained_variance | 7.53e-05      |\n",
      "| fps                | 237           |\n",
      "| n_updates          | 149           |\n",
      "| policy_entropy     | 0.71452564    |\n",
      "| policy_loss        | 0.00024833553 |\n",
      "| serial_timesteps   | 19072         |\n",
      "| time_elapsed       | 77.7          |\n",
      "| total_timesteps    | 19072         |\n",
      "| value_loss         | 70503410.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.393107e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 352           |\n",
      "| ep_reward_mean     | -2.16e+05     |\n",
      "| explained_variance | 0.000218      |\n",
      "| fps                | 236           |\n",
      "| n_updates          | 150           |\n",
      "| policy_entropy     | 0.61066127    |\n",
      "| policy_loss        | 0.00025532662 |\n",
      "| serial_timesteps   | 19200         |\n",
      "| time_elapsed       | 78.2          |\n",
      "| total_timesteps    | 19200         |\n",
      "| value_loss         | 52858950.0    |\n",
      "--------------------------------------\n",
      "Reward -137768.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0001261223 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 350          |\n",
      "| ep_reward_mean     | -2.14e+05    |\n",
      "| explained_variance | 2.71e-05     |\n",
      "| fps                | 310          |\n",
      "| n_updates          | 151          |\n",
      "| policy_entropy     | 0.68886936   |\n",
      "| policy_loss        | 0.0006236207 |\n",
      "| serial_timesteps   | 19328        |\n",
      "| time_elapsed       | 78.8         |\n",
      "| total_timesteps    | 19328        |\n",
      "| value_loss         | 56572292.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0013095665  |\n",
      "| clipfrac           | 0.015625      |\n",
      "| ep_len_mean        | 350           |\n",
      "| ep_reward_mean     | -2.14e+05     |\n",
      "| explained_variance | 0.000163      |\n",
      "| fps                | 223           |\n",
      "| n_updates          | 152           |\n",
      "| policy_entropy     | 0.6887637     |\n",
      "| policy_loss        | -0.0041111964 |\n",
      "| serial_timesteps   | 19456         |\n",
      "| time_elapsed       | 79.2          |\n",
      "| total_timesteps    | 19456         |\n",
      "| value_loss         | 72040800.0    |\n",
      "--------------------------------------\n",
      "Reward -131844.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0039539537 |\n",
      "| clipfrac           | 0.064453125  |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.13e+05    |\n",
      "| explained_variance | -5.79e-05    |\n",
      "| fps                | 254          |\n",
      "| n_updates          | 153          |\n",
      "| policy_entropy     | 0.8843237    |\n",
      "| policy_loss        | 0.0022415787 |\n",
      "| serial_timesteps   | 19584        |\n",
      "| time_elapsed       | 79.7         |\n",
      "| total_timesteps    | 19584        |\n",
      "| value_loss         | 31720162.0   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.006462626  |\n",
      "| clipfrac           | 0.103515625  |\n",
      "| ep_len_mean        | 348          |\n",
      "| ep_reward_mean     | -2.13e+05    |\n",
      "| explained_variance | 0.000148     |\n",
      "| fps                | 317          |\n",
      "| n_updates          | 154          |\n",
      "| policy_entropy     | 1.0566818    |\n",
      "| policy_loss        | -0.004294411 |\n",
      "| serial_timesteps   | 19712        |\n",
      "| time_elapsed       | 80.2         |\n",
      "| total_timesteps    | 19712        |\n",
      "| value_loss         | 86163980.0   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -154776.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016875115 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 347           |\n",
      "| ep_reward_mean     | -2.12e+05     |\n",
      "| explained_variance | -1.34e-05     |\n",
      "| fps                | 312           |\n",
      "| n_updates          | 155           |\n",
      "| policy_entropy     | 1.0089362     |\n",
      "| policy_loss        | 0.0034775934  |\n",
      "| serial_timesteps   | 19840         |\n",
      "| time_elapsed       | 80.7          |\n",
      "| total_timesteps    | 19840         |\n",
      "| value_loss         | 41984040.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016016018 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 347           |\n",
      "| ep_reward_mean     | -2.12e+05     |\n",
      "| explained_variance | 0.00013       |\n",
      "| fps                | 335           |\n",
      "| n_updates          | 156           |\n",
      "| policy_entropy     | 1.0573775     |\n",
      "| policy_loss        | -6.759999e-05 |\n",
      "| serial_timesteps   | 19968         |\n",
      "| time_elapsed       | 81.1          |\n",
      "| total_timesteps    | 19968         |\n",
      "| value_loss         | 73332296.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 20000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -211896.18\n",
      "Reward -177594.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00034149364 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 346           |\n",
      "| ep_reward_mean     | -2.11e+05     |\n",
      "| explained_variance | 2.27e-05      |\n",
      "| fps                | 302           |\n",
      "| n_updates          | 157           |\n",
      "| policy_entropy     | 1.0398554     |\n",
      "| policy_loss        | -0.0012397978 |\n",
      "| serial_timesteps   | 20096         |\n",
      "| time_elapsed       | 81.4          |\n",
      "| total_timesteps    | 20096         |\n",
      "| value_loss         | 79207370.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00089881173 |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| ep_len_mean        | 346           |\n",
      "| ep_reward_mean     | -2.11e+05     |\n",
      "| explained_variance | 0.000253      |\n",
      "| fps                | 353           |\n",
      "| n_updates          | 158           |\n",
      "| policy_entropy     | 1.065595      |\n",
      "| policy_loss        | -0.0034941426 |\n",
      "| serial_timesteps   | 20224         |\n",
      "| time_elapsed       | 81.9          |\n",
      "| total_timesteps    | 20224         |\n",
      "| value_loss         | 40353136.0    |\n",
      "--------------------------------------\n",
      "Reward -139924.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011486133  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 344           |\n",
      "| ep_reward_mean     | -2.1e+05      |\n",
      "| explained_variance | 6.59e-05      |\n",
      "| fps                | 328           |\n",
      "| n_updates          | 159           |\n",
      "| policy_entropy     | 0.9790994     |\n",
      "| policy_loss        | -0.0022782576 |\n",
      "| serial_timesteps   | 20352         |\n",
      "| time_elapsed       | 82.2          |\n",
      "| total_timesteps    | 20352         |\n",
      "| value_loss         | 71640984.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013924163 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 344           |\n",
      "| ep_reward_mean     | -2.1e+05      |\n",
      "| explained_variance | 0.000201      |\n",
      "| fps                | 332           |\n",
      "| n_updates          | 160           |\n",
      "| policy_entropy     | 0.9414399     |\n",
      "| policy_loss        | 0.00043776876 |\n",
      "| serial_timesteps   | 20480         |\n",
      "| time_elapsed       | 82.6          |\n",
      "| total_timesteps    | 20480         |\n",
      "| value_loss         | 46556636.0    |\n",
      "--------------------------------------\n",
      "Reward -159648.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045001548 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 343           |\n",
      "| ep_reward_mean     | -2.09e+05     |\n",
      "| explained_variance | 7.65e-05      |\n",
      "| fps                | 201           |\n",
      "| n_updates          | 161           |\n",
      "| policy_entropy     | 0.9634948     |\n",
      "| policy_loss        | 0.0005468532  |\n",
      "| serial_timesteps   | 20608         |\n",
      "| time_elapsed       | 83            |\n",
      "| total_timesteps    | 20608         |\n",
      "| value_loss         | 86652020.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039313367 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| ep_len_mean        | 343           |\n",
      "| ep_reward_mean     | -2.09e+05     |\n",
      "| explained_variance | 0.00029       |\n",
      "| fps                | 186           |\n",
      "| n_updates          | 162           |\n",
      "| policy_entropy     | 0.9213999     |\n",
      "| policy_loss        | -0.0014015187 |\n",
      "| serial_timesteps   | 20736         |\n",
      "| time_elapsed       | 83.7          |\n",
      "| total_timesteps    | 20736         |\n",
      "| value_loss         | 35086840.0    |\n",
      "--------------------------------------\n",
      "Reward -139844.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018907359 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -2.08e+05     |\n",
      "| explained_variance | 0.000116      |\n",
      "| fps                | 245           |\n",
      "| n_updates          | 163           |\n",
      "| policy_entropy     | 0.9445736     |\n",
      "| policy_loss        | -0.0003156208 |\n",
      "| serial_timesteps   | 20864         |\n",
      "| time_elapsed       | 84.3          |\n",
      "| total_timesteps    | 20864         |\n",
      "| value_loss         | 76990550.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003249464  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 341           |\n",
      "| ep_reward_mean     | -2.08e+05     |\n",
      "| explained_variance | 0.000277      |\n",
      "| fps                | 333           |\n",
      "| n_updates          | 164           |\n",
      "| policy_entropy     | 0.8658147     |\n",
      "| policy_loss        | -0.0025705558 |\n",
      "| serial_timesteps   | 20992         |\n",
      "| time_elapsed       | 84.9          |\n",
      "| total_timesteps    | 20992         |\n",
      "| value_loss         | 38176404.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 21000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -208181.84\n",
      "Reward -132892.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0048132367 |\n",
      "| clipfrac           | 0.01953125   |\n",
      "| ep_len_mean        | 340          |\n",
      "| ep_reward_mean     | -2.07e+05    |\n",
      "| explained_variance | 0.000114     |\n",
      "| fps                | 396          |\n",
      "| n_updates          | 165          |\n",
      "| policy_entropy     | 1.0818776    |\n",
      "| policy_loss        | -0.005488716 |\n",
      "| serial_timesteps   | 21120        |\n",
      "| time_elapsed       | 85.2         |\n",
      "| total_timesteps    | 21120        |\n",
      "| value_loss         | 66270084.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018541425 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 340           |\n",
      "| ep_reward_mean     | -2.07e+05     |\n",
      "| explained_variance | 0.00028       |\n",
      "| fps                | 309           |\n",
      "| n_updates          | 166           |\n",
      "| policy_entropy     | 1.0570768     |\n",
      "| policy_loss        | -0.0011629026 |\n",
      "| serial_timesteps   | 21248         |\n",
      "| time_elapsed       | 85.6          |\n",
      "| total_timesteps    | 21248         |\n",
      "| value_loss         | 38266730.0    |\n",
      "--------------------------------------\n",
      "Reward -155778.0\n",
      "--------------------------------------\n",
      "| approxkl           | 6.4537026e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -2.06e+05     |\n",
      "| explained_variance | 0.000151      |\n",
      "| fps                | 275           |\n",
      "| n_updates          | 167           |\n",
      "| policy_entropy     | 1.1366422     |\n",
      "| policy_loss        | 6.647443e-05  |\n",
      "| serial_timesteps   | 21376         |\n",
      "| time_elapsed       | 86            |\n",
      "| total_timesteps    | 21376         |\n",
      "| value_loss         | 91133200.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2557938e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -2.06e+05     |\n",
      "| explained_variance | 0.000446      |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 168           |\n",
      "| policy_entropy     | 1.0877504     |\n",
      "| policy_loss        | 0.00011611497 |\n",
      "| serial_timesteps   | 21504         |\n",
      "| time_elapsed       | 86.5          |\n",
      "| total_timesteps    | 21504         |\n",
      "| value_loss         | 14006748.0    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00017882636 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -2.06e+05     |\n",
      "| explained_variance | 0.000626      |\n",
      "| fps                | 178           |\n",
      "| n_updates          | 169           |\n",
      "| policy_entropy     | 1.1182269     |\n",
      "| policy_loss        | -0.0005461122 |\n",
      "| serial_timesteps   | 21632         |\n",
      "| time_elapsed       | 87.1          |\n",
      "| total_timesteps    | 21632         |\n",
      "| value_loss         | 112935770.0   |\n",
      "--------------------------------------\n",
      "Reward -200470.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00050452293 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -2.06e+05     |\n",
      "| explained_variance | -9.24e-05     |\n",
      "| fps                | 253           |\n",
      "| n_updates          | 170           |\n",
      "| policy_entropy     | 1.0996783     |\n",
      "| policy_loss        | -0.0015949174 |\n",
      "| serial_timesteps   | 21760         |\n",
      "| time_elapsed       | 87.8          |\n",
      "| total_timesteps    | 21760         |\n",
      "| value_loss         | 29773728.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016368353  |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| ep_len_mean        | 339           |\n",
      "| ep_reward_mean     | -2.06e+05     |\n",
      "| explained_variance | 0.000246      |\n",
      "| fps                | 198           |\n",
      "| n_updates          | 171           |\n",
      "| policy_entropy     | 0.97562325    |\n",
      "| policy_loss        | -0.0054101115 |\n",
      "| serial_timesteps   | 21888         |\n",
      "| time_elapsed       | 88.3          |\n",
      "| total_timesteps    | 21888         |\n",
      "| value_loss         | 86187656.0    |\n",
      "--------------------------------------\n",
      "Reward -148826.0\n",
      "Num timesteps: 22000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -205247.05\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0039383704 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 338          |\n",
      "| ep_reward_mean     | -2.05e+05    |\n",
      "| explained_variance | -7.24e-05    |\n",
      "| fps                | 257          |\n",
      "| n_updates          | 172          |\n",
      "| policy_entropy     | 0.9409666    |\n",
      "| policy_loss        | 0.009391572  |\n",
      "| serial_timesteps   | 22016        |\n",
      "| time_elapsed       | 89           |\n",
      "| total_timesteps    | 22016        |\n",
      "| value_loss         | 35751124.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00116343    |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| ep_len_mean        | 338           |\n",
      "| ep_reward_mean     | -2.05e+05     |\n",
      "| explained_variance | 0.000208      |\n",
      "| fps                | 149           |\n",
      "| n_updates          | 173           |\n",
      "| policy_entropy     | 0.7423284     |\n",
      "| policy_loss        | -0.0022881785 |\n",
      "| serial_timesteps   | 22144         |\n",
      "| time_elapsed       | 89.5          |\n",
      "| total_timesteps    | 22144         |\n",
      "| value_loss         | 83964024.0    |\n",
      "--------------------------------------\n",
      "Reward -129900.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0003446913 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 336          |\n",
      "| ep_reward_mean     | -2.04e+05    |\n",
      "| explained_variance | -0.000189    |\n",
      "| fps                | 191          |\n",
      "| n_updates          | 174          |\n",
      "| policy_entropy     | 0.8189054    |\n",
      "| policy_loss        | 0.0016950429 |\n",
      "| serial_timesteps   | 22272        |\n",
      "| time_elapsed       | 90.3         |\n",
      "| total_timesteps    | 22272        |\n",
      "| value_loss         | 19282340.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005436525  |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| ep_len_mean        | 336           |\n",
      "| ep_reward_mean     | -2.04e+05     |\n",
      "| explained_variance | 0.000435      |\n",
      "| fps                | 258           |\n",
      "| n_updates          | 175           |\n",
      "| policy_entropy     | 0.73504037    |\n",
      "| policy_loss        | 0.00061025255 |\n",
      "| serial_timesteps   | 22400         |\n",
      "| time_elapsed       | 91            |\n",
      "| total_timesteps    | 22400         |\n",
      "| value_loss         | 104193520.0   |\n",
      "--------------------------------------\n",
      "Reward -139774.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019534201 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 335           |\n",
      "| ep_reward_mean     | -2.03e+05     |\n",
      "| explained_variance | -0.000183     |\n",
      "| fps                | 297           |\n",
      "| n_updates          | 176           |\n",
      "| policy_entropy     | 0.85460144    |\n",
      "| policy_loss        | 0.0015442058  |\n",
      "| serial_timesteps   | 22528         |\n",
      "| time_elapsed       | 91.5          |\n",
      "| total_timesteps    | 22528         |\n",
      "| value_loss         | 10966050.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038413212 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 335           |\n",
      "| ep_reward_mean     | -2.03e+05     |\n",
      "| explained_variance | 0.000436      |\n",
      "| fps                | 273           |\n",
      "| n_updates          | 177           |\n",
      "| policy_entropy     | 0.7825018     |\n",
      "| policy_loss        | -0.0010771955 |\n",
      "| serial_timesteps   | 22656         |\n",
      "| time_elapsed       | 91.9          |\n",
      "| total_timesteps    | 22656         |\n",
      "| value_loss         | 108380610.0   |\n",
      "--------------------------------------\n",
      "Reward -142764.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0029068664 |\n",
      "| clipfrac           | 0.0546875    |\n",
      "| ep_len_mean        | 334          |\n",
      "| ep_reward_mean     | -2.02e+05    |\n",
      "| explained_variance | -0.000187    |\n",
      "| fps                | 290          |\n",
      "| n_updates          | 178          |\n",
      "| policy_entropy     | 0.9463007    |\n",
      "| policy_loss        | 0.0125060305 |\n",
      "| serial_timesteps   | 22784        |\n",
      "| time_elapsed       | 92.4         |\n",
      "| total_timesteps    | 22784        |\n",
      "| value_loss         | 9491931.0    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.442811e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 334           |\n",
      "| ep_reward_mean     | -2.02e+05     |\n",
      "| explained_variance | 0.000385      |\n",
      "| fps                | 282           |\n",
      "| n_updates          | 179           |\n",
      "| policy_entropy     | 0.929682      |\n",
      "| policy_loss        | -0.0002089641 |\n",
      "| serial_timesteps   | 22912         |\n",
      "| time_elapsed       | 92.9          |\n",
      "| total_timesteps    | 22912         |\n",
      "| value_loss         | 112455920.0   |\n",
      "--------------------------------------\n",
      "Reward -132836.0\n",
      "Num timesteps: 23000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -201309.16\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006038772 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 332          |\n",
      "| ep_reward_mean     | -2.01e+05    |\n",
      "| explained_variance | 0.000348     |\n",
      "| fps                | 281          |\n",
      "| n_updates          | 180          |\n",
      "| policy_entropy     | 0.86869186   |\n",
      "| policy_loss        | -0.004333209 |\n",
      "| serial_timesteps   | 23040        |\n",
      "| time_elapsed       | 93.3         |\n",
      "| total_timesteps    | 23040        |\n",
      "| value_loss         | 9821787.0    |\n",
      "-------------------------------------\n",
      "Reward -139836.0\n",
      "--------------------------------------\n",
      "| approxkl           | 7.728934e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 331           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.000209      |\n",
      "| fps                | 282           |\n",
      "| n_updates          | 181           |\n",
      "| policy_entropy     | 0.9083113     |\n",
      "| policy_loss        | -0.0003435586 |\n",
      "| serial_timesteps   | 23168         |\n",
      "| time_elapsed       | 93.8          |\n",
      "| total_timesteps    | 23168         |\n",
      "| value_loss         | 107192504.0   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.2682761e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 331            |\n",
      "| ep_reward_mean     | -2e+05         |\n",
      "| explained_variance | 0.000325       |\n",
      "| fps                | 332            |\n",
      "| n_updates          | 182            |\n",
      "| policy_entropy     | 0.81789184     |\n",
      "| policy_loss        | -0.00074079284 |\n",
      "| serial_timesteps   | 23296          |\n",
      "| time_elapsed       | 94.2           |\n",
      "| total_timesteps    | 23296          |\n",
      "| value_loss         | 19344598.0     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -145790.0\n",
      "--------------------------------------\n",
      "| approxkl           | 1.6326501e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 330           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.000188      |\n",
      "| fps                | 320           |\n",
      "| n_updates          | 183           |\n",
      "| policy_entropy     | 0.90645844    |\n",
      "| policy_loss        | 3.0260999e-06 |\n",
      "| serial_timesteps   | 23424         |\n",
      "| time_elapsed       | 94.6          |\n",
      "| total_timesteps    | 23424         |\n",
      "| value_loss         | 100701160.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.100682e-07  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 330           |\n",
      "| ep_reward_mean     | -2e+05        |\n",
      "| explained_variance | 0.000344      |\n",
      "| fps                | 355           |\n",
      "| n_updates          | 184           |\n",
      "| policy_entropy     | 0.80823785    |\n",
      "| policy_loss        | -8.997158e-05 |\n",
      "| serial_timesteps   | 23552         |\n",
      "| time_elapsed       | 95            |\n",
      "| total_timesteps    | 23552         |\n",
      "| value_loss         | 25037578.0    |\n",
      "--------------------------------------\n",
      "Reward -130870.0\n",
      "--------------------------------------\n",
      "| approxkl           | 6.4791607e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 328           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | 0.000179      |\n",
      "| fps                | 452           |\n",
      "| n_updates          | 185           |\n",
      "| policy_entropy     | 0.9142769     |\n",
      "| policy_loss        | 0.00012967596 |\n",
      "| serial_timesteps   | 23680         |\n",
      "| time_elapsed       | 95.4          |\n",
      "| total_timesteps    | 23680         |\n",
      "| value_loss         | 77999010.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2434535e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 328           |\n",
      "| ep_reward_mean     | -1.99e+05     |\n",
      "| explained_variance | 0.000251      |\n",
      "| fps                | 418           |\n",
      "| n_updates          | 186           |\n",
      "| policy_entropy     | 0.8051323     |\n",
      "| policy_loss        | -6.822171e-05 |\n",
      "| serial_timesteps   | 23808         |\n",
      "| time_elapsed       | 95.7          |\n",
      "| total_timesteps    | 23808         |\n",
      "| value_loss         | 43370660.0    |\n",
      "--------------------------------------\n",
      "Reward -142750.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010989268  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 327           |\n",
      "| ep_reward_mean     | -1.98e+05     |\n",
      "| explained_variance | 0.000106      |\n",
      "| fps                | 305           |\n",
      "| n_updates          | 187           |\n",
      "| policy_entropy     | 0.96026665    |\n",
      "| policy_loss        | -0.0037776898 |\n",
      "| serial_timesteps   | 23936         |\n",
      "| time_elapsed       | 96            |\n",
      "| total_timesteps    | 23936         |\n",
      "| value_loss         | 71528344.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 24000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -197994.22\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00032263435 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 327           |\n",
      "| ep_reward_mean     | -1.98e+05     |\n",
      "| explained_variance | 0.000309      |\n",
      "| fps                | 156           |\n",
      "| n_updates          | 188           |\n",
      "| policy_entropy     | 0.8756277     |\n",
      "| policy_loss        | -0.0025229412 |\n",
      "| serial_timesteps   | 24064         |\n",
      "| time_elapsed       | 96.4          |\n",
      "| total_timesteps    | 24064         |\n",
      "| value_loss         | 46550880.0    |\n",
      "--------------------------------------\n",
      "Reward -138826.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015046403  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 326           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 8.48e-05      |\n",
      "| fps                | 273           |\n",
      "| n_updates          | 189           |\n",
      "| policy_entropy     | 0.92936575    |\n",
      "| policy_loss        | -0.0034725082 |\n",
      "| serial_timesteps   | 24192         |\n",
      "| time_elapsed       | 97.2          |\n",
      "| total_timesteps    | 24192         |\n",
      "| value_loss         | 64088304.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.3719646e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 326           |\n",
      "| ep_reward_mean     | -1.97e+05     |\n",
      "| explained_variance | 0.000219      |\n",
      "| fps                | 258           |\n",
      "| n_updates          | 190           |\n",
      "| policy_entropy     | 0.7066615     |\n",
      "| policy_loss        | 0.00010037166 |\n",
      "| serial_timesteps   | 24320         |\n",
      "| time_elapsed       | 97.7          |\n",
      "| total_timesteps    | 24320         |\n",
      "| value_loss         | 61373204.0    |\n",
      "--------------------------------------\n",
      "Reward -136828.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0026083412  |\n",
      "| clipfrac           | 0.0390625     |\n",
      "| ep_len_mean        | 325           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | -4.77e-06     |\n",
      "| fps                | 306           |\n",
      "| n_updates          | 191           |\n",
      "| policy_entropy     | 0.9502951     |\n",
      "| policy_loss        | -0.0005111105 |\n",
      "| serial_timesteps   | 24448         |\n",
      "| time_elapsed       | 98.2          |\n",
      "| total_timesteps    | 24448         |\n",
      "| value_loss         | 47116830.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004735021  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 325           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000175      |\n",
      "| fps                | 310           |\n",
      "| n_updates          | 192           |\n",
      "| policy_entropy     | 0.8066206     |\n",
      "| policy_loss        | 0.00031979883 |\n",
      "| serial_timesteps   | 24576         |\n",
      "| time_elapsed       | 98.6          |\n",
      "| total_timesteps    | 24576         |\n",
      "| value_loss         | 76431240.0    |\n",
      "--------------------------------------\n",
      "Reward -128932.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014522854  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 324           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | -0.000137     |\n",
      "| fps                | 372           |\n",
      "| n_updates          | 193           |\n",
      "| policy_entropy     | 0.8868719     |\n",
      "| policy_loss        | -0.0065299324 |\n",
      "| serial_timesteps   | 24704         |\n",
      "| time_elapsed       | 99            |\n",
      "| total_timesteps    | 24704         |\n",
      "| value_loss         | 24862672.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009818358  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 324           |\n",
      "| ep_reward_mean     | -1.96e+05     |\n",
      "| explained_variance | 0.000345      |\n",
      "| fps                | 400           |\n",
      "| n_updates          | 194           |\n",
      "| policy_entropy     | 0.7265138     |\n",
      "| policy_loss        | -0.0025623506 |\n",
      "| serial_timesteps   | 24832         |\n",
      "| time_elapsed       | 99.4          |\n",
      "| total_timesteps    | 24832         |\n",
      "| value_loss         | 101360410.0   |\n",
      "--------------------------------------\n",
      "Reward -130856.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.008806788  |\n",
      "| clipfrac           | 0.11328125   |\n",
      "| ep_len_mean        | 323          |\n",
      "| ep_reward_mean     | -1.95e+05    |\n",
      "| explained_variance | -0.000154    |\n",
      "| fps                | 340          |\n",
      "| n_updates          | 195          |\n",
      "| policy_entropy     | 1.0121       |\n",
      "| policy_loss        | -0.003055487 |\n",
      "| serial_timesteps   | 24960        |\n",
      "| time_elapsed       | 99.7         |\n",
      "| total_timesteps    | 24960        |\n",
      "| value_loss         | 7029117.0    |\n",
      "-------------------------------------\n",
      "Num timesteps: 25000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -194714.55\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045804973 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 323           |\n",
      "| ep_reward_mean     | -1.95e+05     |\n",
      "| explained_variance | 0.000481      |\n",
      "| fps                | 274           |\n",
      "| n_updates          | 196           |\n",
      "| policy_entropy     | 1.0560994     |\n",
      "| policy_loss        | -0.0014023818 |\n",
      "| serial_timesteps   | 25088         |\n",
      "| time_elapsed       | 100           |\n",
      "| total_timesteps    | 25088         |\n",
      "| value_loss         | 112682500.0   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -133888.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014077564 |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| ep_len_mean        | 322          |\n",
      "| ep_reward_mean     | -1.94e+05    |\n",
      "| explained_variance | 0.000648     |\n",
      "| fps                | 332          |\n",
      "| n_updates          | 197          |\n",
      "| policy_entropy     | 1.1018809    |\n",
      "| policy_loss        | 0.0005200895 |\n",
      "| serial_timesteps   | 25216        |\n",
      "| time_elapsed       | 101          |\n",
      "| total_timesteps    | 25216        |\n",
      "| value_loss         | 4567775.0    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002121978  |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| ep_len_mean        | 322          |\n",
      "| ep_reward_mean     | -1.94e+05    |\n",
      "| explained_variance | 0.000452     |\n",
      "| fps                | 296          |\n",
      "| n_updates          | 198          |\n",
      "| policy_entropy     | 1.1686385    |\n",
      "| policy_loss        | -0.003828421 |\n",
      "| serial_timesteps   | 25344        |\n",
      "| time_elapsed       | 101          |\n",
      "| total_timesteps    | 25344        |\n",
      "| value_loss         | 112799020.0  |\n",
      "-------------------------------------\n",
      "Reward -140886.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0063887914  |\n",
      "| clipfrac           | 0.03515625    |\n",
      "| ep_len_mean        | 321           |\n",
      "| ep_reward_mean     | -1.93e+05     |\n",
      "| explained_variance | 0.00105       |\n",
      "| fps                | 236           |\n",
      "| n_updates          | 199           |\n",
      "| policy_entropy     | 1.1918373     |\n",
      "| policy_loss        | -0.0051473975 |\n",
      "| serial_timesteps   | 25472         |\n",
      "| time_elapsed       | 101           |\n",
      "| total_timesteps    | 25472         |\n",
      "| value_loss         | 1811965.9     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013316658 |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| ep_len_mean        | 321          |\n",
      "| ep_reward_mean     | -1.93e+05    |\n",
      "| explained_variance | 0.000503     |\n",
      "| fps                | 302          |\n",
      "| n_updates          | 200          |\n",
      "| policy_entropy     | 1.196904     |\n",
      "| policy_loss        | -0.002866277 |\n",
      "| serial_timesteps   | 25600        |\n",
      "| time_elapsed       | 102          |\n",
      "| total_timesteps    | 25600        |\n",
      "| value_loss         | 112784424.0  |\n",
      "-------------------------------------\n",
      "Reward -140876.0\n",
      "---------------------------------------\n",
      "| approxkl           | 0.003355064    |\n",
      "| clipfrac           | 0.03515625     |\n",
      "| ep_len_mean        | 320            |\n",
      "| ep_reward_mean     | -1.93e+05      |\n",
      "| explained_variance | -0.000465      |\n",
      "| fps                | 307            |\n",
      "| n_updates          | 201            |\n",
      "| policy_entropy     | 1.2983116      |\n",
      "| policy_loss        | -5.4697506e-05 |\n",
      "| serial_timesteps   | 25728          |\n",
      "| time_elapsed       | 102            |\n",
      "| total_timesteps    | 25728          |\n",
      "| value_loss         | 569165.56      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0021699609 |\n",
      "| clipfrac           | 0.025390625  |\n",
      "| ep_len_mean        | 320          |\n",
      "| ep_reward_mean     | -1.93e+05    |\n",
      "| explained_variance | 0.000473     |\n",
      "| fps                | 324          |\n",
      "| n_updates          | 202          |\n",
      "| policy_entropy     | 1.3176161    |\n",
      "| policy_loss        | -0.008387878 |\n",
      "| serial_timesteps   | 25856        |\n",
      "| time_elapsed       | 103          |\n",
      "| total_timesteps    | 25856        |\n",
      "| value_loss         | 110779510.0  |\n",
      "-------------------------------------\n",
      "Reward -167770.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0039593326  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.92e+05     |\n",
      "| explained_variance | -1.92e-05     |\n",
      "| fps                | 312           |\n",
      "| n_updates          | 203           |\n",
      "| policy_entropy     | 1.3789551     |\n",
      "| policy_loss        | -0.0034229173 |\n",
      "| serial_timesteps   | 25984         |\n",
      "| time_elapsed       | 103           |\n",
      "| total_timesteps    | 25984         |\n",
      "| value_loss         | 28801292.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 26000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -192351.11\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018170034  |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.92e+05     |\n",
      "| explained_variance | 0.000102      |\n",
      "| fps                | 222           |\n",
      "| n_updates          | 204           |\n",
      "| policy_entropy     | 1.3621963     |\n",
      "| policy_loss        | -0.0049036006 |\n",
      "| serial_timesteps   | 26112         |\n",
      "| time_elapsed       | 104           |\n",
      "| total_timesteps    | 26112         |\n",
      "| value_loss         | 57381924.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.006176946   |\n",
      "| clipfrac           | 0.16210938    |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.92e+05     |\n",
      "| explained_variance | 0.000118      |\n",
      "| fps                | 262           |\n",
      "| n_updates          | 205           |\n",
      "| policy_entropy     | 1.3543394     |\n",
      "| policy_loss        | -0.0029461645 |\n",
      "| serial_timesteps   | 26240         |\n",
      "| time_elapsed       | 104           |\n",
      "| total_timesteps    | 26240         |\n",
      "| value_loss         | 112973150.0   |\n",
      "--------------------------------------\n",
      "Reward -211424.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0016600719 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 320          |\n",
      "| ep_reward_mean     | -1.93e+05    |\n",
      "| explained_variance | -0.000108    |\n",
      "| fps                | 286          |\n",
      "| n_updates          | 206          |\n",
      "| policy_entropy     | 1.3526278    |\n",
      "| policy_loss        | -0.00750174  |\n",
      "| serial_timesteps   | 26368        |\n",
      "| time_elapsed       | 105          |\n",
      "| total_timesteps    | 26368        |\n",
      "| value_loss         | 3961590.5    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00068864087 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.93e+05     |\n",
      "| explained_variance | 0.000136      |\n",
      "| fps                | 261           |\n",
      "| n_updates          | 207           |\n",
      "| policy_entropy     | 1.3038102     |\n",
      "| policy_loss        | -0.0015655777 |\n",
      "| serial_timesteps   | 26496         |\n",
      "| time_elapsed       | 105           |\n",
      "| total_timesteps    | 26496         |\n",
      "| value_loss         | 94691550.0    |\n",
      "--------------------------------------\n",
      "Reward -152852.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00212111   |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 320          |\n",
      "| ep_reward_mean     | -1.92e+05    |\n",
      "| explained_variance | -6.79e-06    |\n",
      "| fps                | 275          |\n",
      "| n_updates          | 208          |\n",
      "| policy_entropy     | 1.3816803    |\n",
      "| policy_loss        | 0.0042241532 |\n",
      "| serial_timesteps   | 26624        |\n",
      "| time_elapsed       | 106          |\n",
      "| total_timesteps    | 26624        |\n",
      "| value_loss         | 31780208.0   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0027978243 |\n",
      "| clipfrac           | 0.041015625  |\n",
      "| ep_len_mean        | 320          |\n",
      "| ep_reward_mean     | -1.92e+05    |\n",
      "| explained_variance | 7.5e-05      |\n",
      "| fps                | 258          |\n",
      "| n_updates          | 209          |\n",
      "| policy_entropy     | 1.3597437    |\n",
      "| policy_loss        | -0.004809917 |\n",
      "| serial_timesteps   | 26752        |\n",
      "| time_elapsed       | 106          |\n",
      "| total_timesteps    | 26752        |\n",
      "| value_loss         | 43629230.0   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0021554881 |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| ep_len_mean        | 320          |\n",
      "| ep_reward_mean     | -1.92e+05    |\n",
      "| explained_variance | 0.000129     |\n",
      "| fps                | 338          |\n",
      "| n_updates          | 210          |\n",
      "| policy_entropy     | 1.3628116    |\n",
      "| policy_loss        | -0.005324283 |\n",
      "| serial_timesteps   | 26880        |\n",
      "| time_elapsed       | 107          |\n",
      "| total_timesteps    | 26880        |\n",
      "| value_loss         | 113010910.0  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward -246202.0\n",
      "Num timesteps: 27000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -192784.74\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0033262847 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 321          |\n",
      "| ep_reward_mean     | -1.93e+05    |\n",
      "| explained_variance | -1.07e-05    |\n",
      "| fps                | 304          |\n",
      "| n_updates          | 211          |\n",
      "| policy_entropy     | 1.3161175    |\n",
      "| policy_loss        | -0.013165023 |\n",
      "| serial_timesteps   | 27008        |\n",
      "| time_elapsed       | 107          |\n",
      "| total_timesteps    | 27008        |\n",
      "| value_loss         | 46172630.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012606717 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 321           |\n",
      "| ep_reward_mean     | -1.93e+05     |\n",
      "| explained_variance | 4.12e-05      |\n",
      "| fps                | 285           |\n",
      "| n_updates          | 212           |\n",
      "| policy_entropy     | 1.1711137     |\n",
      "| policy_loss        | -0.0004013441 |\n",
      "| serial_timesteps   | 27136         |\n",
      "| time_elapsed       | 107           |\n",
      "| total_timesteps    | 27136         |\n",
      "| value_loss         | 58351584.0    |\n",
      "--------------------------------------\n",
      "Reward -179688.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017893311 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 321           |\n",
      "| ep_reward_mean     | -1.93e+05     |\n",
      "| explained_variance | 4.04e-05      |\n",
      "| fps                | 241           |\n",
      "| n_updates          | 213           |\n",
      "| policy_entropy     | 1.2923564     |\n",
      "| policy_loss        | 0.00029582263 |\n",
      "| serial_timesteps   | 27264         |\n",
      "| time_elapsed       | 108           |\n",
      "| total_timesteps    | 27264         |\n",
      "| value_loss         | 96602990.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.696564e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 321           |\n",
      "| ep_reward_mean     | -1.93e+05     |\n",
      "| explained_variance | 0.000199      |\n",
      "| fps                | 329           |\n",
      "| n_updates          | 214           |\n",
      "| policy_entropy     | 1.1632667     |\n",
      "| policy_loss        | 0.00037312845 |\n",
      "| serial_timesteps   | 27392         |\n",
      "| time_elapsed       | 108           |\n",
      "| total_timesteps    | 27392         |\n",
      "| value_loss         | 13946608.0    |\n",
      "--------------------------------------\n",
      "Reward -132960.0\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9370684e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.92e+05     |\n",
      "| explained_variance | 0.000129      |\n",
      "| fps                | 334           |\n",
      "| n_updates          | 215           |\n",
      "| policy_entropy     | 1.2704451     |\n",
      "| policy_loss        | 9.023055e-05  |\n",
      "| serial_timesteps   | 27520         |\n",
      "| time_elapsed       | 109           |\n",
      "| total_timesteps    | 27520         |\n",
      "| value_loss         | 93276860.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.784037e-08   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 320            |\n",
      "| ep_reward_mean     | -1.92e+05      |\n",
      "| explained_variance | 0.000429       |\n",
      "| fps                | 369            |\n",
      "| n_updates          | 216            |\n",
      "| policy_entropy     | 1.208283       |\n",
      "| policy_loss        | -1.2057135e-05 |\n",
      "| serial_timesteps   | 27648          |\n",
      "| time_elapsed       | 109            |\n",
      "| total_timesteps    | 27648          |\n",
      "| value_loss         | 4288169.5      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.826147e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 320           |\n",
      "| ep_reward_mean     | -1.92e+05     |\n",
      "| explained_variance | 0.000325      |\n",
      "| fps                | 367           |\n",
      "| n_updates          | 217           |\n",
      "| policy_entropy     | 1.2280291     |\n",
      "| policy_loss        | -0.0006329644 |\n",
      "| serial_timesteps   | 27776         |\n",
      "| time_elapsed       | 109           |\n",
      "| total_timesteps    | 27776         |\n",
      "| value_loss         | 112810040.0   |\n",
      "--------------------------------------\n",
      "Reward -138834.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007135551  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 319           |\n",
      "| ep_reward_mean     | -1.91e+05     |\n",
      "| explained_variance | 0.000536      |\n",
      "| fps                | 359           |\n",
      "| n_updates          | 218           |\n",
      "| policy_entropy     | 1.2093889     |\n",
      "| policy_loss        | -0.0008575334 |\n",
      "| serial_timesteps   | 27904         |\n",
      "| time_elapsed       | 110           |\n",
      "| total_timesteps    | 27904         |\n",
      "| value_loss         | 4294271.0     |\n",
      "--------------------------------------\n",
      "Num timesteps: 28000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -191360.92\n",
      "Reward -131988.0\n",
      "--------------------------------------\n",
      "| approxkl           | 6.2705825e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 318           |\n",
      "| ep_reward_mean     | -1.91e+05     |\n",
      "| explained_variance | 0.000291      |\n",
      "| fps                | 358           |\n",
      "| n_updates          | 219           |\n",
      "| policy_entropy     | 1.2589144     |\n",
      "| policy_loss        | 0.0002445808  |\n",
      "| serial_timesteps   | 28032         |\n",
      "| time_elapsed       | 110           |\n",
      "| total_timesteps    | 28032         |\n",
      "| value_loss         | 106265460.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8986495e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 318           |\n",
      "| ep_reward_mean     | -1.91e+05     |\n",
      "| explained_variance | 0.00117       |\n",
      "| fps                | 368           |\n",
      "| n_updates          | 220           |\n",
      "| policy_entropy     | 1.2544261     |\n",
      "| policy_loss        | -0.0001737217 |\n",
      "| serial_timesteps   | 28160         |\n",
      "| time_elapsed       | 110           |\n",
      "| total_timesteps    | 28160         |\n",
      "| value_loss         | 1370548.8     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00023383764  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 318            |\n",
      "| ep_reward_mean     | -1.91e+05      |\n",
      "| explained_variance | 0.000626       |\n",
      "| fps                | 444            |\n",
      "| n_updates          | 221            |\n",
      "| policy_entropy     | 1.2377694      |\n",
      "| policy_loss        | -0.00010402384 |\n",
      "| serial_timesteps   | 28288          |\n",
      "| time_elapsed       | 111            |\n",
      "| total_timesteps    | 28288          |\n",
      "| value_loss         | 112764560.0    |\n",
      "---------------------------------------\n",
      "Reward -144800.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033805356 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 318           |\n",
      "| ep_reward_mean     | -1.9e+05      |\n",
      "| explained_variance | -0.000378     |\n",
      "| fps                | 244           |\n",
      "| n_updates          | 222           |\n",
      "| policy_entropy     | 1.306901      |\n",
      "| policy_loss        | -0.0016137785 |\n",
      "| serial_timesteps   | 28416         |\n",
      "| time_elapsed       | 111           |\n",
      "| total_timesteps    | 28416         |\n",
      "| value_loss         | 1861149.6     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.3666525e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 318           |\n",
      "| ep_reward_mean     | -1.9e+05      |\n",
      "| explained_variance | 0.000561      |\n",
      "| fps                | 321           |\n",
      "| n_updates          | 223           |\n",
      "| policy_entropy     | 1.25438       |\n",
      "| policy_loss        | 0.00024016039 |\n",
      "| serial_timesteps   | 28544         |\n",
      "| time_elapsed       | 112           |\n",
      "| total_timesteps    | 28544         |\n",
      "| value_loss         | 112744040.0   |\n",
      "--------------------------------------\n",
      "Reward -142932.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00036368123 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 317           |\n",
      "| ep_reward_mean     | -1.9e+05      |\n",
      "| explained_variance | -0.000176     |\n",
      "| fps                | 427           |\n",
      "| n_updates          | 224           |\n",
      "| policy_entropy     | 1.3326124     |\n",
      "| policy_loss        | 0.0039096344  |\n",
      "| serial_timesteps   | 28672         |\n",
      "| time_elapsed       | 112           |\n",
      "| total_timesteps    | 28672         |\n",
      "| value_loss         | 4472893.0     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 0.00031791226  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 317            |\n",
      "| ep_reward_mean     | -1.9e+05       |\n",
      "| explained_variance | 0.000269       |\n",
      "| fps                | 419            |\n",
      "| n_updates          | 225            |\n",
      "| policy_entropy     | 1.1835035      |\n",
      "| policy_loss        | -0.00042053603 |\n",
      "| serial_timesteps   | 28800          |\n",
      "| time_elapsed       | 112            |\n",
      "| total_timesteps    | 28800          |\n",
      "| value_loss         | 99695400.0     |\n",
      "---------------------------------------\n",
      "Reward -160808.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002313415   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 317           |\n",
      "| ep_reward_mean     | -1.89e+05     |\n",
      "| explained_variance | -4.53e-06     |\n",
      "| fps                | 349           |\n",
      "| n_updates          | 226           |\n",
      "| policy_entropy     | 1.3650385     |\n",
      "| policy_loss        | -0.0029877117 |\n",
      "| serial_timesteps   | 28928         |\n",
      "| time_elapsed       | 113           |\n",
      "| total_timesteps    | 28928         |\n",
      "| value_loss         | 34806140.0    |\n",
      "--------------------------------------\n",
      "Num timesteps: 29000\n",
      "Best mean reward: -135505.50 - Last mean reward per episode: -189372.84\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0009550074   |\n",
      "| clipfrac           | 0.0078125      |\n",
      "| ep_len_mean        | 317            |\n",
      "| ep_reward_mean     | -1.89e+05      |\n",
      "| explained_variance | 0.000144       |\n",
      "| fps                | 335            |\n",
      "| n_updates          | 227            |\n",
      "| policy_entropy     | 1.1770631      |\n",
      "| policy_loss        | -9.0757734e-05 |\n",
      "| serial_timesteps   | 29056          |\n",
      "| time_elapsed       | 113            |\n",
      "| total_timesteps    | 29056          |\n",
      "| value_loss         | 44462820.0     |\n",
      "---------------------------------------\n",
      "Reward -130934.0\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002645345 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 317          |\n",
      "| ep_reward_mean     | -1.89e+05    |\n",
      "| explained_variance | 9.47e-05     |\n",
      "| fps                | 356          |\n",
      "| n_updates          | 228          |\n",
      "| policy_entropy     | 1.369166     |\n",
      "| policy_loss        | 0.00078518   |\n",
      "| serial_timesteps   | 29184        |\n",
      "| time_elapsed       | 113          |\n",
      "| total_timesteps    | 29184        |\n",
      "| value_loss         | 57824228.0   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.6437574e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 317           |\n",
      "| ep_reward_mean     | -1.89e+05     |\n",
      "| explained_variance | 0.000241      |\n",
      "| fps                | 300           |\n",
      "| n_updates          | 229           |\n",
      "| policy_entropy     | 1.2844493     |\n",
      "| policy_loss        | 0.0012493051  |\n",
      "| serial_timesteps   | 29312         |\n",
      "| time_elapsed       | 114           |\n",
      "| total_timesteps    | 29312         |\n",
      "| value_loss         | 17545460.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014669923  |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| ep_len_mean        | 317           |\n",
      "| ep_reward_mean     | -1.89e+05     |\n",
      "| explained_variance | 0.000355      |\n",
      "| fps                | 285           |\n",
      "| n_updates          | 230           |\n",
      "| policy_entropy     | 1.3536026     |\n",
      "| policy_loss        | -0.0058997255 |\n",
      "| serial_timesteps   | 29440         |\n",
      "| time_elapsed       | 114           |\n",
      "| total_timesteps    | 29440         |\n",
      "| value_loss         | 113036520.0   |\n",
      "--------------------------------------\n",
      "Reward -156786.0\n",
      "------------------------------------\n",
      "| approxkl           | 0.006939793 |\n",
      "| clipfrac           | 0.025390625 |\n",
      "| ep_len_mean        | 317         |\n",
      "| ep_reward_mean     | -1.88e+05   |\n",
      "| explained_variance | -0.000225   |\n",
      "| fps                | 330         |\n",
      "| n_updates          | 231         |\n",
      "| policy_entropy     | 1.2503542   |\n",
      "| policy_loss        | -0.00537691 |\n",
      "| serial_timesteps   | 29568       |\n",
      "| time_elapsed       | 115         |\n",
      "| total_timesteps    | 29568       |\n",
      "| value_loss         | 24929.377   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00017674587  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 317            |\n",
      "| ep_reward_mean     | -1.88e+05      |\n",
      "| explained_variance | 0.000468       |\n",
      "| fps                | 301            |\n",
      "| n_updates          | 232            |\n",
      "| policy_entropy     | 1.1544818      |\n",
      "| policy_loss        | -0.00015835633 |\n",
      "| serial_timesteps   | 29696          |\n",
      "| time_elapsed       | 115            |\n",
      "| total_timesteps    | 29696          |\n",
      "| value_loss         | 112800570.0    |\n",
      "---------------------------------------\n",
      "Reward -141870.0\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00031708187 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 316           |\n",
      "| ep_reward_mean     | -1.88e+05     |\n",
      "| explained_variance | -0.000202     |\n",
      "| fps                | 254           |\n",
      "| n_updates          | 233           |\n",
      "| policy_entropy     | 1.2430218     |\n",
      "| policy_loss        | 0.00176755    |\n",
      "| serial_timesteps   | 29824         |\n",
      "| time_elapsed       | 115           |\n",
      "| total_timesteps    | 29824         |\n",
      "| value_loss         | 3479589.2     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.095527e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 316           |\n",
      "| ep_reward_mean     | -1.88e+05     |\n",
      "| explained_variance | 0.000305      |\n",
      "| fps                | 239           |\n",
      "| n_updates          | 234           |\n",
      "| policy_entropy     | 1.134116      |\n",
      "| policy_loss        | 0.00027541164 |\n",
      "| serial_timesteps   | 29952         |\n",
      "| time_elapsed       | 116           |\n",
      "| total_timesteps    | 29952         |\n",
      "| value_loss         | 106114344.0   |\n",
      "--------------------------------------\n",
      "PPO2**********************************************\n",
      "Reward -109348.0\n",
      "Reward =  -110348.0\n",
      "Total infected : 1.0928696543780736\n",
      "Total cost 0\n",
      "201\n",
      "0.19367197298168584\n",
      "201\n",
      "0.19367197298168584\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#DQN,PPO\n",
    "run_algos_plot(30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Economic budget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN,PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With -ve reward for new infection\n",
    "#With -ve reward for infection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Move the peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQN,PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limiting Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1  Reducing compliance -area under curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN,PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1  Reducing changes -area under curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN,PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Age group based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action dim== 8\n",
      "episode: 1, total reward: 1878.0\n",
      "episode: 2, total reward: -8688.75\n",
      "episode: 3, total reward: 405.5\n",
      "episode: 4, total reward: 371.75\n",
      "episode: 5, total reward: 380.0\n",
      "episode: 6, total reward: 408.0\n",
      "episode: 7, total reward: 402.0\n",
      "episode: 8, total reward: 438.0\n",
      "episode: 9, total reward: -8449.25\n",
      "episode: 10, total reward: -8602.25\n",
      "episode: 11, total reward: -8541.0\n",
      "episode: 12, total reward: 399.25\n",
      "episode: 13, total reward: 390.75\n",
      "episode: 14, total reward: 384.0\n",
      "episode: 15, total reward: 398.25\n",
      "episode: 16, total reward: 382.5\n",
      "episode: 17, total reward: 381.75\n",
      "episode: 18, total reward: 380.75\n",
      "episode: 19, total reward: 368.25\n",
      "episode: 20, total reward: 387.75\n",
      "episode: 21, total reward: 377.75\n",
      "episode: 22, total reward: 373.5\n",
      "episode: 23, total reward: 370.0\n",
      "episode: 24, total reward: 392.25\n",
      "episode: 25, total reward: 399.5\n",
      "episode: 26, total reward: 382.5\n",
      "episode: 27, total reward: 382.5\n",
      "episode: 28, total reward: 396.5\n",
      "episode: 29, total reward: 397.75\n",
      "episode: 30, total reward: 373.0\n",
      "episode: 31, total reward: 403.75\n",
      "episode: 32, total reward: 366.5\n",
      "episode: 33, total reward: 403.0\n",
      "episode: 34, total reward: 387.25\n",
      "episode: 35, total reward: 378.75\n",
      "episode: 36, total reward: 372.5\n",
      "episode: 37, total reward: 401.25\n",
      "episode: 38, total reward: 396.0\n",
      "episode: 39, total reward: 401.25\n",
      "episode: 40, total reward: 2347.25\n",
      "episode: 41, total reward: -8183.5\n",
      "episode: 42, total reward: -8361.25\n",
      "episode: 43, total reward: -8367.25\n",
      "episode: 44, total reward: -8354.75\n",
      "episode: 45, total reward: 436.75\n",
      "episode: 46, total reward: 350.0\n",
      "episode: 47, total reward: 363.5\n",
      "episode: 48, total reward: 376.0\n",
      "episode: 49, total reward: 389.5\n",
      "episode: 50, total reward: 376.5\n",
      "episode: 51, total reward: 360.0\n",
      "episode: 52, total reward: 360.0\n",
      "episode: 53, total reward: 351.75\n",
      "episode: 54, total reward: 375.25\n",
      "episode: 55, total reward: 360.5\n",
      "episode: 56, total reward: 378.75\n",
      "episode: 57, total reward: 366.5\n",
      "episode: 58, total reward: 364.75\n",
      "episode: 59, total reward: 364.75\n",
      "episode: 60, total reward: 374.75\n",
      "episode: 61, total reward: 363.5\n",
      "episode: 62, total reward: 371.25\n",
      "episode: 63, total reward: 364.75\n",
      "episode: 64, total reward: 379.0\n",
      "episode: 65, total reward: 366.0\n",
      "episode: 66, total reward: 389.0\n",
      "episode: 67, total reward: 358.25\n",
      "episode: 68, total reward: 378.25\n",
      "episode: 69, total reward: 363.5\n",
      "episode: 70, total reward: 368.75\n",
      "episode: 71, total reward: 381.75\n",
      "episode: 72, total reward: 366.0\n",
      "episode: 73, total reward: 391.75\n",
      "episode: 74, total reward: 355.25\n",
      "episode: 75, total reward: 370.5\n",
      "episode: 76, total reward: 377.25\n",
      "episode: 77, total reward: 380.25\n",
      "episode: 78, total reward: 377.0\n",
      "episode: 79, total reward: 371.75\n",
      "episode: 80, total reward: 395.25\n",
      "episode: 81, total reward: 363.5\n",
      "episode: 82, total reward: -8431.0\n",
      "episode: 83, total reward: 404.75\n",
      "episode: 84, total reward: 369.5\n",
      "episode: 85, total reward: 381.25\n",
      "episode: 86, total reward: 364.25\n",
      "episode: 87, total reward: 365.25\n",
      "episode: 88, total reward: 366.5\n",
      "episode: 89, total reward: 359.5\n",
      "episode: 90, total reward: 368.75\n",
      "episode: 91, total reward: 369.5\n",
      "episode: 92, total reward: 369.5\n",
      "episode: 93, total reward: 365.25\n",
      "episode: 94, total reward: 371.25\n",
      "episode: 95, total reward: 355.25\n",
      "episode: 96, total reward: 359.5\n",
      "episode: 97, total reward: 358.25\n",
      "episode: 98, total reward: 356.5\n",
      "episode: 99, total reward: 358.25\n",
      "episode: 100, total reward: 384.75\n",
      "episode: 101, total reward: 351.75\n",
      "episode: 102, total reward: 360.0\n",
      "episode: 103, total reward: 358.25\n",
      "episode: 104, total reward: 373.0\n",
      "episode: 105, total reward: 366.0\n",
      "episode: 106, total reward: 366.0\n",
      "episode: 107, total reward: 367.0\n",
      "episode: 108, total reward: 1267.75\n",
      "episode: 109, total reward: -8813.5\n",
      "episode: 110, total reward: -8791.0\n",
      "episode: 111, total reward: -8766.5\n",
      "episode: 112, total reward: -8749.0\n",
      "episode: 113, total reward: -9274.25\n",
      "episode: 114, total reward: -8775.25\n",
      "episode: 115, total reward: -7656.75\n",
      "episode: 116, total reward: -8592.75\n",
      "episode: 117, total reward: -8343.5\n",
      "episode: 118, total reward: -8304.0\n",
      "episode: 119, total reward: -8289.25\n",
      "episode: 120, total reward: -8273.75\n",
      "episode: 121, total reward: -8563.5\n",
      "episode: 122, total reward: -8330.25\n",
      "episode: 123, total reward: -8202.75\n",
      "episode: 124, total reward: -8069.5\n",
      "episode: 125, total reward: -8286.5\n",
      "episode: 126, total reward: -6847.0\n",
      "episode: 127, total reward: -7014.25\n",
      "episode: 128, total reward: -7525.75\n",
      "episode: 129, total reward: 3735.5\n",
      "episode: 130, total reward: 3180.5\n",
      "episode: 131, total reward: 3519.5\n",
      "episode: 132, total reward: 3683.25\n",
      "episode: 133, total reward: -5314.0\n",
      "episode: 134, total reward: -7037.25\n",
      "episode: 135, total reward: -7139.25\n",
      "episode: 136, total reward: 4652.5\n",
      "episode: 137, total reward: 3562.25\n",
      "episode: 138, total reward: 2661.75\n",
      "episode: 139, total reward: 2779.5\n",
      "episode: 140, total reward: 2464.0\n",
      "episode: 141, total reward: 2743.75\n",
      "episode: 142, total reward: 2559.0\n",
      "episode: 143, total reward: 1585.0\n",
      "episode: 144, total reward: -8649.5\n",
      "episode: 145, total reward: -8603.25\n",
      "episode: 146, total reward: 2313.0\n",
      "episode: 147, total reward: 2451.75\n",
      "episode: 148, total reward: 2535.5\n",
      "episode: 149, total reward: 2824.5\n",
      "episode: 150, total reward: 2462.25\n",
      "episode: 151, total reward: 2312.0\n",
      "episode: 152, total reward: 4253.25\n",
      "episode: 153, total reward: -8481.0\n",
      "episode: 154, total reward: 404.75\n",
      "episode: 155, total reward: 2405.5\n",
      "episode: 156, total reward: 2593.5\n",
      "episode: 157, total reward: 2592.25\n",
      "episode: 158, total reward: 2747.25\n",
      "episode: 159, total reward: 2461.75\n",
      "episode: 160, total reward: -8791.75\n",
      "episode: 161, total reward: 2441.5\n",
      "episode: 162, total reward: 2682.25\n",
      "episode: 163, total reward: 2589.25\n",
      "episode: 164, total reward: 2566.5\n",
      "episode: 165, total reward: 2613.75\n",
      "episode: 166, total reward: 2625.75\n",
      "episode: 167, total reward: -7977.75\n",
      "episode: 168, total reward: -8578.25\n",
      "episode: 169, total reward: -8582.25\n",
      "episode: 170, total reward: 388.0\n",
      "episode: 171, total reward: 368.25\n",
      "episode: 172, total reward: 360.0\n",
      "episode: 173, total reward: 367.75\n",
      "episode: 174, total reward: 356.5\n",
      "episode: 175, total reward: 378.25\n",
      "episode: 176, total reward: 358.25\n",
      "episode: 177, total reward: 370.5\n",
      "episode: 178, total reward: 360.5\n",
      "episode: 179, total reward: 356.5\n",
      "episode: 180, total reward: 364.25\n",
      "episode: 181, total reward: 358.75\n",
      "episode: 182, total reward: 366.5\n",
      "episode: 183, total reward: 366.0\n",
      "episode: 184, total reward: 366.5\n",
      "episode: 185, total reward: 389.0\n",
      "episode: 186, total reward: 397.75\n",
      "episode: 187, total reward: 360.0\n",
      "episode: 188, total reward: 364.25\n",
      "episode: 189, total reward: 381.25\n",
      "episode: 190, total reward: 366.5\n",
      "episode: 191, total reward: 368.75\n",
      "episode: 192, total reward: 350.0\n",
      "episode: 193, total reward: 379.5\n",
      "episode: 194, total reward: 367.75\n",
      "episode: 195, total reward: 2645.25\n",
      "episode: 196, total reward: 3107.75\n",
      "episode: 197, total reward: -8381.75\n",
      "episode: 198, total reward: 2306.75\n",
      "episode: 199, total reward: 2484.0\n",
      "episode: 200, total reward: 2570.25\n",
      "episode: 201, total reward: 2868.25\n",
      "episode: 202, total reward: -7326.25\n",
      "episode: 203, total reward: 2464.75\n",
      "episode: 204, total reward: 2448.75\n",
      "episode: 205, total reward: 2564.0\n",
      "episode: 206, total reward: 2348.0\n",
      "episode: 207, total reward: 2793.75\n",
      "episode: 208, total reward: 3133.75\n",
      "episode: 209, total reward: -8490.75\n",
      "episode: 210, total reward: -8009.5\n",
      "episode: 211, total reward: -8014.75\n",
      "episode: 212, total reward: -8400.5\n",
      "episode: 213, total reward: -8650.75\n",
      "episode: 214, total reward: 411.5\n",
      "episode: 215, total reward: 363.0\n",
      "episode: 216, total reward: 373.5\n",
      "episode: 217, total reward: 367.0\n",
      "episode: 218, total reward: 370.5\n",
      "episode: 219, total reward: 358.25\n",
      "episode: 220, total reward: 377.0\n",
      "episode: 221, total reward: 370.0\n",
      "episode: 222, total reward: 386.5\n",
      "episode: 223, total reward: 350.0\n",
      "episode: 224, total reward: 363.5\n",
      "episode: 225, total reward: 397.75\n",
      "episode: 226, total reward: 369.5\n",
      "episode: 227, total reward: 366.5\n",
      "episode: 228, total reward: 374.75\n",
      "episode: 229, total reward: 365.25\n",
      "episode: 230, total reward: 361.75\n",
      "episode: 231, total reward: 377.75\n",
      "episode: 232, total reward: 350.0\n",
      "episode: 233, total reward: 366.5\n",
      "episode: 234, total reward: 366.0\n",
      "episode: 235, total reward: 373.5\n",
      "episode: 236, total reward: 358.25\n",
      "episode: 237, total reward: 507.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 238, total reward: 2442.5\n",
      "episode: 239, total reward: 409.75\n",
      "episode: 240, total reward: -8830.25\n",
      "episode: 241, total reward: 2651.25\n",
      "episode: 242, total reward: 2617.0\n",
      "episode: 243, total reward: 2850.0\n",
      "episode: 244, total reward: 2265.75\n",
      "episode: 245, total reward: -8641.5\n",
      "episode: 246, total reward: 2496.25\n",
      "episode: 247, total reward: 2654.5\n",
      "episode: 248, total reward: 2531.75\n",
      "episode: 249, total reward: 2655.25\n",
      "episode: 250, total reward: 2332.75\n",
      "episode: 251, total reward: 3151.25\n",
      "episode: 252, total reward: 1167.5\n",
      "episode: 253, total reward: 1152.75\n",
      "episode: 254, total reward: 1188.5\n",
      "episode: 255, total reward: -7913.0\n",
      "episode: 256, total reward: 389.5\n",
      "episode: 257, total reward: 381.75\n",
      "episode: 258, total reward: 368.25\n",
      "episode: 259, total reward: 371.25\n",
      "episode: 260, total reward: 357.0\n",
      "episode: 261, total reward: 370.0\n",
      "episode: 262, total reward: 370.0\n",
      "episode: 263, total reward: 371.75\n",
      "episode: 264, total reward: 360.0\n",
      "episode: 265, total reward: 371.75\n",
      "episode: 266, total reward: 373.0\n",
      "episode: 267, total reward: 373.5\n",
      "episode: 268, total reward: 369.5\n",
      "episode: 269, total reward: 369.5\n",
      "episode: 270, total reward: 360.0\n",
      "episode: 271, total reward: 370.75\n",
      "episode: 272, total reward: 363.5\n",
      "episode: 273, total reward: -8543.0\n",
      "episode: 274, total reward: 2460.0\n",
      "episode: 275, total reward: 2412.25\n",
      "episode: 276, total reward: 2609.0\n",
      "episode: 277, total reward: 2379.0\n",
      "episode: 278, total reward: 2746.5\n",
      "episode: 279, total reward: -8365.75\n",
      "episode: 280, total reward: -8036.5\n",
      "episode: 281, total reward: -8241.0\n",
      "episode: 282, total reward: 371.25\n",
      "episode: 283, total reward: 353.5\n",
      "episode: 284, total reward: 373.0\n",
      "episode: 285, total reward: 369.5\n",
      "episode: 286, total reward: 376.5\n",
      "episode: 287, total reward: 361.75\n",
      "episode: 288, total reward: 360.0\n",
      "episode: 289, total reward: 368.25\n",
      "episode: 290, total reward: 366.5\n",
      "episode: 291, total reward: 377.5\n",
      "episode: 292, total reward: 368.25\n",
      "episode: 293, total reward: 363.5\n",
      "episode: 294, total reward: 365.25\n",
      "episode: 295, total reward: 364.75\n",
      "episode: 296, total reward: 357.0\n",
      "episode: 297, total reward: 373.5\n",
      "episode: 298, total reward: 363.0\n",
      "episode: 299, total reward: 350.0\n",
      "episode: 300, total reward: 376.0\n",
      "episode: 301, total reward: 380.75\n",
      "episode: 302, total reward: 365.25\n",
      "episode: 303, total reward: 363.5\n",
      "episode: 304, total reward: -8312.0\n",
      "episode: 305, total reward: 386.0\n",
      "episode: 306, total reward: 369.5\n",
      "episode: 307, total reward: 356.5\n",
      "episode: 308, total reward: 366.0\n",
      "episode: 309, total reward: 369.5\n",
      "episode: 310, total reward: 360.5\n",
      "episode: 311, total reward: 373.5\n",
      "episode: 312, total reward: 366.5\n",
      "episode: 313, total reward: 361.25\n",
      "episode: 314, total reward: 353.5\n",
      "episode: 315, total reward: 371.25\n",
      "episode: 316, total reward: 353.5\n",
      "episode: 317, total reward: 367.5\n",
      "episode: 318, total reward: 370.0\n",
      "episode: 319, total reward: 361.25\n",
      "episode: 320, total reward: 2643.5\n",
      "episode: 321, total reward: -8435.0\n",
      "episode: 322, total reward: -8583.5\n",
      "episode: 323, total reward: -4663.0\n",
      "episode: 324, total reward: 386.75\n",
      "episode: 325, total reward: 370.0\n",
      "episode: 326, total reward: 364.75\n",
      "episode: 327, total reward: 371.75\n",
      "episode: 328, total reward: 354.75\n",
      "episode: 329, total reward: 358.75\n",
      "episode: 330, total reward: 364.75\n",
      "episode: 331, total reward: 367.0\n",
      "episode: 332, total reward: 360.0\n",
      "episode: 333, total reward: 355.25\n",
      "episode: 334, total reward: 353.0\n",
      "episode: 335, total reward: 378.25\n",
      "episode: 336, total reward: 365.25\n",
      "episode: 337, total reward: 370.0\n",
      "episode: 338, total reward: 367.0\n",
      "episode: 339, total reward: 354.75\n",
      "episode: 340, total reward: 358.25\n",
      "episode: 341, total reward: 351.75\n",
      "episode: 342, total reward: 361.25\n",
      "episode: 343, total reward: 368.25\n",
      "episode: 344, total reward: 361.25\n",
      "episode: 345, total reward: 387.5\n",
      "episode: 346, total reward: 382.5\n",
      "episode: 347, total reward: 1262.5\n",
      "episode: 348, total reward: -8805.75\n",
      "episode: 349, total reward: 433.5\n",
      "episode: 350, total reward: 353.5\n",
      "episode: 351, total reward: 364.75\n",
      "episode: 352, total reward: 364.75\n",
      "episode: 353, total reward: 367.0\n",
      "episode: 354, total reward: 360.5\n",
      "episode: 355, total reward: 371.75\n",
      "episode: 356, total reward: 360.0\n",
      "episode: 357, total reward: 363.0\n",
      "episode: 358, total reward: 357.0\n",
      "episode: 359, total reward: 360.0\n",
      "episode: 360, total reward: 362.25\n",
      "episode: 361, total reward: 387.0\n",
      "episode: 362, total reward: 373.0\n",
      "episode: 363, total reward: 1709.5\n",
      "episode: 364, total reward: -8686.75\n",
      "episode: 365, total reward: 2415.25\n",
      "episode: 366, total reward: 2624.25\n",
      "episode: 367, total reward: 2500.5\n",
      "episode: 368, total reward: 2559.5\n",
      "episode: 369, total reward: 2508.75\n",
      "episode: 370, total reward: -8477.0\n",
      "episode: 371, total reward: 1101.0\n",
      "episode: 372, total reward: -7798.5\n",
      "episode: 373, total reward: -8422.75\n",
      "episode: 374, total reward: 391.0\n",
      "episode: 375, total reward: 373.5\n",
      "episode: 376, total reward: 388.75\n",
      "episode: 377, total reward: 354.75\n",
      "episode: 378, total reward: 369.5\n",
      "episode: 379, total reward: 364.75\n",
      "episode: 380, total reward: 364.75\n",
      "episode: 381, total reward: 358.25\n",
      "episode: 382, total reward: 361.75\n",
      "episode: 383, total reward: 388.25\n",
      "episode: 384, total reward: 357.75\n",
      "episode: 385, total reward: 366.0\n",
      "episode: 386, total reward: 367.0\n",
      "episode: 387, total reward: 358.25\n",
      "episode: 388, total reward: 363.0\n",
      "episode: 389, total reward: 361.75\n",
      "episode: 390, total reward: 362.5\n",
      "episode: 391, total reward: 2804.5\n",
      "episode: 392, total reward: 2106.75\n",
      "episode: 393, total reward: -8555.5\n",
      "episode: 394, total reward: 398.0\n",
      "episode: 395, total reward: 350.0\n",
      "episode: 396, total reward: 358.75\n",
      "episode: 397, total reward: 350.0\n",
      "episode: 398, total reward: 370.0\n",
      "episode: 399, total reward: 367.0\n",
      "episode: 400, total reward: 366.5\n",
      "episode: 401, total reward: 373.5\n",
      "episode: 402, total reward: 375.25\n",
      "episode: 403, total reward: 366.0\n",
      "episode: 404, total reward: 359.5\n",
      "episode: 405, total reward: 363.0\n",
      "episode: 406, total reward: 358.25\n",
      "episode: 407, total reward: 358.25\n",
      "episode: 408, total reward: 361.75\n",
      "episode: 409, total reward: 369.5\n",
      "episode: 410, total reward: 358.25\n",
      "episode: 411, total reward: 469.75\n",
      "episode: 412, total reward: -8468.0\n",
      "episode: 413, total reward: 2414.25\n",
      "episode: 414, total reward: 2796.5\n",
      "episode: 415, total reward: 2356.25\n",
      "episode: 416, total reward: 2854.25\n",
      "episode: 417, total reward: 2540.25\n",
      "episode: 418, total reward: -8405.5\n",
      "episode: 419, total reward: 394.0\n",
      "episode: 420, total reward: 378.25\n",
      "episode: 421, total reward: 361.25\n",
      "episode: 422, total reward: 361.25\n",
      "episode: 423, total reward: 365.25\n",
      "episode: 424, total reward: 376.5\n",
      "episode: 425, total reward: 360.0\n",
      "episode: 426, total reward: 379.5\n",
      "episode: 427, total reward: 368.75\n",
      "episode: 428, total reward: 367.0\n",
      "episode: 429, total reward: 358.25\n",
      "episode: 430, total reward: 368.25\n",
      "episode: 431, total reward: 3693.0\n",
      "episode: 432, total reward: 2765.75\n",
      "episode: 433, total reward: -8299.0\n",
      "episode: 434, total reward: 369.5\n",
      "episode: 435, total reward: 362.5\n",
      "episode: 436, total reward: 361.75\n",
      "episode: 437, total reward: 350.0\n",
      "episode: 438, total reward: 354.75\n",
      "episode: 439, total reward: 350.0\n",
      "episode: 440, total reward: 373.0\n",
      "episode: 441, total reward: 363.5\n",
      "episode: 442, total reward: 354.75\n",
      "episode: 443, total reward: 356.5\n",
      "episode: 444, total reward: 368.75\n",
      "episode: 445, total reward: 381.75\n",
      "episode: 446, total reward: 365.25\n",
      "episode: 447, total reward: 382.5\n",
      "episode: 448, total reward: 2696.0\n",
      "episode: 449, total reward: 2518.75\n",
      "episode: 450, total reward: -6981.0\n",
      "episode: 451, total reward: -8197.0\n",
      "episode: 452, total reward: -8595.0\n",
      "episode: 453, total reward: 380.25\n",
      "episode: 454, total reward: 361.25\n",
      "episode: 455, total reward: 370.75\n",
      "episode: 456, total reward: 361.75\n",
      "episode: 457, total reward: 366.5\n",
      "episode: 458, total reward: 355.25\n",
      "episode: 459, total reward: 356.5\n",
      "episode: 460, total reward: 371.25\n",
      "episode: 461, total reward: 358.75\n",
      "episode: 462, total reward: 354.75\n",
      "episode: 463, total reward: 350.0\n",
      "episode: 464, total reward: 366.5\n",
      "episode: 465, total reward: 364.75\n",
      "episode: 466, total reward: 361.25\n",
      "episode: 467, total reward: 353.5\n",
      "episode: 468, total reward: 366.5\n",
      "episode: 469, total reward: 360.0\n",
      "episode: 470, total reward: 382.0\n",
      "episode: 471, total reward: 2807.5\n",
      "episode: 472, total reward: 2674.75\n",
      "episode: 473, total reward: 1167.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 474, total reward: -8689.5\n",
      "episode: 475, total reward: -8909.5\n",
      "episode: 476, total reward: -8412.0\n",
      "episode: 477, total reward: 405.75\n",
      "episode: 478, total reward: 365.25\n",
      "episode: 479, total reward: 362.5\n",
      "episode: 480, total reward: 365.25\n",
      "episode: 481, total reward: 371.25\n",
      "episode: 482, total reward: 366.0\n",
      "episode: 483, total reward: 386.0\n",
      "episode: 484, total reward: 361.75\n",
      "episode: 485, total reward: 355.25\n",
      "episode: 486, total reward: 365.25\n",
      "episode: 487, total reward: 360.75\n",
      "episode: 488, total reward: 391.25\n",
      "episode: 489, total reward: 385.25\n",
      "episode: 490, total reward: 363.5\n",
      "episode: 491, total reward: 381.75\n",
      "episode: 492, total reward: 356.5\n",
      "episode: 493, total reward: 361.25\n",
      "episode: 494, total reward: 363.5\n",
      "episode: 495, total reward: 373.5\n",
      "episode: 496, total reward: 356.5\n",
      "episode: 497, total reward: 350.0\n",
      "episode: 498, total reward: 377.75\n",
      "episode: 499, total reward: 370.0\n",
      "episode: 500, total reward: 358.25\n",
      "episode: 501, total reward: 364.0\n",
      "episode: 502, total reward: 364.0\n",
      "episode: 503, total reward: -8831.75\n",
      "episode: 504, total reward: 381.75\n",
      "episode: 505, total reward: 401.25\n",
      "episode: 506, total reward: 363.5\n",
      "episode: 507, total reward: 354.75\n",
      "episode: 508, total reward: 369.0\n",
      "episode: 509, total reward: 363.0\n",
      "episode: 510, total reward: 358.75\n",
      "episode: 511, total reward: 381.25\n",
      "episode: 512, total reward: 380.5\n",
      "episode: 513, total reward: 583.0\n",
      "episode: 514, total reward: -8943.75\n",
      "episode: 515, total reward: -8181.75\n",
      "episode: 516, total reward: 390.5\n",
      "episode: 517, total reward: 350.0\n",
      "episode: 518, total reward: 387.75\n",
      "episode: 519, total reward: 363.0\n",
      "episode: 520, total reward: 385.75\n",
      "episode: 521, total reward: 366.5\n",
      "episode: 522, total reward: 350.0\n",
      "episode: 523, total reward: 374.75\n",
      "episode: 524, total reward: 354.75\n",
      "episode: 525, total reward: 364.25\n",
      "episode: 526, total reward: 366.5\n",
      "episode: 527, total reward: 373.0\n",
      "episode: 528, total reward: 366.5\n",
      "episode: 529, total reward: 2762.75\n",
      "episode: 530, total reward: 2727.75\n",
      "episode: 531, total reward: -8645.0\n",
      "episode: 532, total reward: -8822.0\n",
      "episode: 533, total reward: -8973.75\n",
      "episode: 534, total reward: -8603.25\n",
      "episode: 535, total reward: 474.0\n",
      "episode: 536, total reward: 387.5\n",
      "episode: 537, total reward: 371.25\n",
      "episode: 538, total reward: 366.5\n",
      "episode: 539, total reward: 361.75\n",
      "episode: 540, total reward: 353.0\n",
      "episode: 541, total reward: 387.25\n",
      "episode: 542, total reward: 372.5\n",
      "episode: 543, total reward: 363.5\n",
      "episode: 544, total reward: 370.0\n",
      "episode: 545, total reward: 395.5\n",
      "episode: 546, total reward: 370.75\n",
      "episode: 547, total reward: 373.0\n",
      "episode: 548, total reward: 357.75\n",
      "episode: 549, total reward: 376.5\n",
      "episode: 550, total reward: 381.25\n",
      "episode: 551, total reward: 366.5\n",
      "episode: 552, total reward: 387.75\n",
      "episode: 553, total reward: 386.0\n",
      "episode: 554, total reward: 373.0\n",
      "episode: 555, total reward: -8708.5\n",
      "episode: 556, total reward: 387.75\n",
      "episode: 557, total reward: 358.25\n",
      "episode: 558, total reward: 355.25\n",
      "episode: 559, total reward: 353.0\n",
      "episode: 560, total reward: 363.5\n",
      "episode: 561, total reward: 391.25\n",
      "episode: 562, total reward: 364.25\n",
      "episode: 563, total reward: 369.5\n",
      "episode: 564, total reward: 357.75\n",
      "episode: 565, total reward: 354.75\n",
      "episode: 566, total reward: 367.75\n",
      "episode: 567, total reward: 353.5\n",
      "episode: 568, total reward: 377.0\n",
      "episode: 569, total reward: 383.0\n",
      "episode: 570, total reward: 382.5\n",
      "episode: 571, total reward: 374.75\n",
      "episode: 572, total reward: 350.0\n",
      "episode: 573, total reward: 361.25\n",
      "episode: 574, total reward: -8534.5\n",
      "episode: 575, total reward: 422.5\n",
      "episode: 576, total reward: 367.75\n",
      "episode: 577, total reward: 374.25\n",
      "episode: 578, total reward: 392.5\n",
      "episode: 579, total reward: 373.0\n",
      "episode: 580, total reward: 377.25\n",
      "episode: 581, total reward: -8359.75\n",
      "episode: 582, total reward: 398.0\n",
      "episode: 583, total reward: 358.75\n",
      "episode: 584, total reward: 365.25\n",
      "episode: 585, total reward: 360.0\n",
      "episode: 586, total reward: 353.0\n",
      "episode: 587, total reward: 363.5\n",
      "episode: 588, total reward: 363.0\n",
      "episode: 589, total reward: 371.25\n",
      "episode: 590, total reward: 357.0\n",
      "episode: 591, total reward: 354.75\n",
      "episode: 592, total reward: 361.25\n",
      "episode: 593, total reward: 363.5\n",
      "episode: 594, total reward: 376.5\n",
      "episode: 595, total reward: 376.5\n",
      "episode: 596, total reward: 374.75\n",
      "episode: 597, total reward: 378.25\n",
      "episode: 598, total reward: 361.75\n",
      "episode: 599, total reward: 355.25\n",
      "episode: 600, total reward: -8416.0\n",
      "episode: 601, total reward: -8456.0\n",
      "episode: 602, total reward: 2713.0\n",
      "episode: 603, total reward: 2738.5\n",
      "episode: 604, total reward: 2694.0\n",
      "episode: 605, total reward: 2744.5\n",
      "episode: 606, total reward: 2670.75\n",
      "episode: 607, total reward: 2244.75\n",
      "episode: 608, total reward: -8606.25\n",
      "episode: 609, total reward: 2472.75\n",
      "episode: 610, total reward: 2422.5\n",
      "episode: 611, total reward: 2551.0\n",
      "episode: 612, total reward: 2692.25\n",
      "episode: 613, total reward: -8331.0\n",
      "episode: 614, total reward: 2075.5\n",
      "episode: 615, total reward: 2357.75\n",
      "episode: 616, total reward: 2652.25\n",
      "episode: 617, total reward: 2543.25\n",
      "episode: 618, total reward: 3846.5\n",
      "episode: 619, total reward: -8664.75\n",
      "episode: 620, total reward: 2663.75\n"
     ]
    }
   ],
   "source": [
    "#DQN \n",
    "run_algos_plot(30000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Multi agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN,PPO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
